## 案例1：查询每个科目排名前三的学生和成绩
**业务场景**：学校教务系统需要展示各科目成绩前三名的学生名单，用于表彰优秀学生。  
**SQL书写逻辑**：
1. 使用窗口函数DENSE_RANK()按科目分组对成绩进行排名
2. 通过PARTITION BY subject确保每个科目单独排名
3. 筛选rank值小于等于3的记录
4. 按科目和排名排序输出结果

```sql
WITH student_scores AS (
    SELECT
        student_id,
        student_name,
        subject,
        score,
        DENSE_RANK() OVER (PARTITION BY subject ORDER BY score DESC) AS score_rank
    FROM exam_results
)
SELECT
    subject,
    student_name,
    score
FROM student_scores
WHERE score_rank <= 3
ORDER BY subject, score_rank;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE exam_results (
    id INT PRIMARY KEY AUTO_INCREMENT,
    student_id INT NOT NULL,
    student_name VARCHAR(50) NOT NULL,
    class_id VARCHAR(20) NOT NULL,
    subject VARCHAR(30) NOT NULL,
    score DECIMAL(5,2) NOT NULL,
    exam_date DATE NOT NULL,
    INDEX idx_subject_score (subject, score DESC),
    INDEX idx_student (student_id)
);

-- 示例数据
INSERT INTO exam_results (student_id, student_name, class_id, subject, score, exam_date) VALUES
(101, '张三', 'A101', '数学', 95.5, '2023-09-15'),
(101, '张三', 'A101', '语文', 88.0, '2023-09-15'),
(102, '李四', 'A101', '数学', 92.0, '2023-09-15'),
(102, '李四', 'A101', '语文', 85.5, '2023-09-15'),
(103, '王五', 'A101', '数学', 98.0, '2023-09-15'),
(103, '王五', 'A101', '语文', 90.0, '2023-09-15'),
(104, '赵六', 'A101', '数学', 89.0, '2023-09-15'),
(104, '赵六', 'A101', '语文', 92.5, '2023-09-15'),
(105, '钱七', 'A101', '数学', 91.0, '2023-09-15'),
(105, '钱七', 'A101', '语文', 87.0, '2023-09-15');
```

## 案例2：计算某店7月"蚂蚁上树"销量同比增长率
**业务场景**：餐饮连锁企业需要分析各门店招牌菜品的年度销售增长情况。  
**SQL书写逻辑**：
1. 分别查询今年7月和去年7月的销售总量
2. 使用CROSS JOIN将两个结果集合并
3. 计算同比增长率：(今年销量-去年销量)/去年销量*100
4. 保留两位小数输出结果

```sql
SELECT
    current_month.sales AS current_sales,
    last_year.sales AS last_year_sales,
    ROUND((current_month.sales - last_year.sales) / last_year.sales * 100, 2) AS growth_rate
FROM (
    SELECT SUM(quantity) AS sales
    FROM sales_records
    WHERE product_name = '蚂蚁上树'
    AND store_id = 101
    AND sale_date BETWEEN '2023-07-01' AND '2023-07-31'
) AS current_month
CROSS JOIN (
    SELECT SUM(quantity) AS sales
    FROM sales_records
    WHERE product_name = '蚂蚁上树'
    AND store_id = 101
    AND sale_date BETWEEN '2022-07-01' AND '2022-07-31'
) AS last_year;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE sales_records (
    id INT PRIMARY KEY AUTO_INCREMENT,
    store_id INT NOT NULL,
    product_name VARCHAR(50) NOT NULL,
    quantity INT NOT NULL,
    sale_date DATE NOT NULL,
    amount DECIMAL(10,2) NOT NULL,
    INDEX idx_store_product (store_id, product_name),
    INDEX idx_date (sale_date)
);

-- 示例数据
INSERT INTO sales_records (store_id, product_name, quantity, sale_date, amount) VALUES
(101, '蚂蚁上树', 120, '2022-07-01', 2400.00),
(101, '蚂蚁上树', 150, '2022-07-15', 3000.00),
(101, '蚂蚁上树', 80, '2023-07-05', 1600.00),
(101, '蚂蚁上树', 200, '2023-07-20', 4000.00),
(101, '宫保鸡丁', 90, '2023-07-10', 2700.00),
(102, '蚂蚁上树', 70, '2023-07-08', 1400.00);
```

## 案例3：找出连续3天登录的用户
**业务场景**：互联网产品运营需要识别高活跃用户进行精准营销。  
**SQL书写逻辑**：
1. 通过自连接找出同一用户连续3天登录的记录
2. 第一个表(a)作为基准日期
3. 第二个表(b)查找次日登录记录
4. 第三个表(c)查找第三日登录记录
5. 使用DISTINCT去重

```sql
SELECT DISTINCT a.user_id
FROM user_logins a
JOIN user_logins b ON a.user_id = b.user_id
    AND b.login_date = DATE_ADD(a.login_date, INTERVAL 1 DAY)
JOIN user_logins c ON a.user_id = c.user_id
    AND c.login_date = DATE_ADD(a.login_date, INTERVAL 2 DAY)
WHERE a.login_date >= '2023-08-01';
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE user_logins (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    login_date DATE NOT NULL,
    device_type VARCHAR(20),
    INDEX idx_user_date (user_id, login_date)
);

-- 示例数据
INSERT INTO user_logins (user_id, login_date, device_type) VALUES
(1001, '2023-08-01', 'Mobile'),
(1001, '2023-08-02', 'PC'),
(1001, '2023-08-03', 'Mobile'),
(1002, '2023-08-01', 'PC'),
(1002, '2023-08-03', 'Mobile'),
(1003, '2023-08-05', 'Mobile'),
(1003, '2023-08-06', 'Mobile'),
(1003, '2023-08-07', 'PC'),
(1004, '2023-08-10', 'Mobile'),
(1004, '2023-08-11', 'Mobile'),
(1004, '2023-08-12', 'Mobile');
```

## 案例4：计算用户留存率（次日/7日/30日）
**业务场景**：移动应用需要分析不同时期用户的质量和粘性。  
**SQL书写逻辑**：
1. 先找出每个用户的首次登录日
2. 左连接所有登录记录
3. 使用条件聚合计算不同时间窗口的留存用户数
4. 计算留存率并保留两位小数
5. 按首次登录日排序

```sql
SELECT
    first_day,
    COUNT(DISTINCT first_login.user_id) AS new_users,
    ROUND(COUNT(DISTINCT CASE WHEN user_logins.login_date = DATE_ADD(first_day, INTERVAL 1 DAY) THEN first_login.user_id END) /
          COUNT(DISTINCT first_login.user_id) * 100, 2) AS day1_retention,
    ROUND(COUNT(DISTINCT CASE WHEN user_logins.login_date BETWEEN DATE_ADD(first_day, INTERVAL 1 DAY) AND DATE_ADD(first_day, INTERVAL 7 DAY) THEN first_login.user_id END) /
          COUNT(DISTINCT first_login.user_id) * 100, 2) AS day7_retention,
    ROUND(COUNT(DISTINCT CASE WHEN user_logins.login_date BETWEEN DATE_ADD(first_day, INTERVAL 1 DAY) AND DATE_ADD(first_day, INTERVAL 30 DAY) THEN first_login.user_id END) /
          COUNT(DISTINCT first_login.user_id) * 100, 2) AS day30_retention
FROM (
    SELECT
        user_id,
        MIN(login_date) AS first_day
    FROM user_logins
    GROUP BY user_id
) AS first_login
LEFT JOIN user_logins ON user_logins.user_id = first_login.user_id
GROUP BY first_day
ORDER BY first_day;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE user_behavior (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    event_date DATE NOT NULL,
    event_type ENUM('register', 'login', 'purchase') NOT NULL,
    INDEX idx_user_date (user_id, event_date)
);

-- 示例数据
INSERT INTO user_behavior (user_id, event_date, event_type) VALUES
(1001, '2023-10-01', 'register'),
(1001, '2023-10-01', 'login'),
(1001, '2023-10-02', 'login'),
(1001, '2023-10-05', 'purchase'),
(1002, '2023-10-01', 'register'),
(1002, '2023-10-08', 'login'),
(1003, '2023-10-15', 'register'),
(1003, '2023-10-16', 'login'),
(1003, '2023-10-20', 'purchase'),
(1004, '2023-10-01', 'register'),
(1004, '2023-10-02', 'login'),
(1004, '2023-10-30', 'purchase');
```


## 案例5：识别购物篮关联商品（经常一起购买的商品组合）
**业务场景**：电商平台需要分析商品关联性，优化商品推荐和货架摆放。  
**SQL书写逻辑**：
1. 自连接order_items表，查找同一订单中的不同商品
2. 使用a.product_id < b.product_id避免重复组合
3. 按商品组合分组统计出现次数
4. 筛选出现10次以上的组合
5. 按出现次数降序排列，限制输出20条

```sql
SELECT
    a.product_name AS product1,
    b.product_name AS product2,
    COUNT(*) AS combo_count
FROM order_items a
JOIN order_items b ON a.order_id = b.order_id AND a.product_id < b.product_id
GROUP BY a.product_name, b.product_name
HAVING COUNT(*) >= 2
ORDER BY combo_count DESC
LIMIT 20;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE order_items (
    id INT PRIMARY KEY AUTO_INCREMENT,
    order_id INT NOT NULL,
    product_id INT NOT NULL,
    product_name VARCHAR(50) NOT NULL,
    quantity INT NOT NULL,
    price DECIMAL(10,2) NOT NULL,
    INDEX idx_order (order_id),
    INDEX idx_product (product_id)
);

-- 示例数据
INSERT INTO order_items (order_id, product_id, product_name, quantity, price) VALUES
(10001, 101, 'iPhone 13', 1, 5999.00),
(10001, 102, 'AirPods Pro', 1, 1499.00),
(10002, 101, 'iPhone 13', 1, 5999.00),
(10002, 103, 'MagSafe充电器', 1, 329.00),
(10003, 102, 'AirPods Pro', 2, 1499.00),
(10003, 103, 'MagSafe充电器', 1, 329.00),
(10004, 104, 'iPad Air', 1, 4399.00),
(10004, 105, 'Apple Pencil', 1, 999.00),
(10005, 101, 'iPhone 13', 1, 5999.00),
(10005, 105, 'Apple Pencil', 1, 999.00);
```

## 案例6：计算员工薪资部门占比
**业务场景**：HR部门需要分析员工薪资在部门和全公司的占比情况。  
**SQL书写逻辑**：
1. 连接employees和departments表获取完整信息
2. 使用窗口函数计算部门薪资总和(SUM OVER PARTITION BY department_id)
3. 使用窗口函数计算公司总薪资(SUM OVER)
4. 计算个人薪资占比并保留两位小数
5. 按部门和薪资降序排列

```sql
SELECT
    e.employee_id,
    e.employee_name,
    e.salary,
    d.department_name,
    ROUND(e.salary / SUM(e.salary) OVER (PARTITION BY e.department_id) * 100, 2) AS dept_salary_percent,
    ROUND(e.salary / SUM(e.salary) OVER () * 100, 2) AS total_salary_percent
FROM employees e
JOIN departments d ON e.department_id = d.department_id
ORDER BY e.department_id, e.salary DESC;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE departments (
    department_id INT PRIMARY KEY,
    department_name VARCHAR(50) NOT NULL,
    location VARCHAR(50)
);

CREATE TABLE employees (
    employee_id INT PRIMARY KEY,
    employee_name VARCHAR(50) NOT NULL,
    department_id INT,
    salary DECIMAL(10,2) NOT NULL,
    hire_date DATE NOT NULL,
    FOREIGN KEY (department_id) REFERENCES departments(department_id)
);

-- 示例数据
INSERT INTO departments VALUES
(10, '研发部', '北京'),
(20, '市场部', '上海'),
(30, '财务部', '广州');

INSERT INTO employees VALUES
(1001, '张三', 10, 15000.00, '2020-06-15'),
(1002, '李四', 10, 18000.00, '2019-03-10'),
(1003, '王五', 20, 12000.00, '2021-01-20'),
(1004, '赵六', 20, 13500.00, '2020-11-05'),
(1005, '钱七', 30, 20000.00, '2018-07-22'),
(1006, '孙八', 30, 22000.00, '2017-09-30');
```

## 案例7：查询用户最近一次购买距今天数
**业务场景**：电商平台需要识别不同状态的用户群体，制定差异化营销策略。  
**SQL书写逻辑**：
1. 左连接users和orders表
2. 按用户分组找出最近订单日期
3. 计算与当前日期的差值
4. 使用CASE WHEN对用户进行分类
5. 按距今天数降序排列

```sql
SELECT
    u.user_id,
    u.user_name,
    DATEDIFF(CURRENT_DATE, MAX(o.order_date)) AS days_since_last_order,
    CASE
        WHEN DATEDIFF(CURRENT_DATE, MAX(o.order_date)) <= 30 THEN '活跃用户'
        WHEN DATEDIFF(CURRENT_DATE, MAX(o.order_date)) <= 90 THEN '沉默用户'
        ELSE '流失用户'
    END AS user_status
FROM users u
LEFT JOIN orders o ON u.user_id = o.user_id
GROUP BY u.user_id, u.user_name
ORDER BY days_since_last_order DESC;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE users (
    user_id INT PRIMARY KEY,
    user_name VARCHAR(50) NOT NULL,
    register_date DATE NOT NULL,
    phone VARCHAR(20)
);

CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    user_id INT NOT NULL,
    order_date DATETIME NOT NULL,
    amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) NOT NULL,
    FOREIGN KEY (user_id) REFERENCES users(user_id),
    INDEX idx_user_date (user_id, order_date)
);

-- 示例数据
INSERT INTO users VALUES
(1001, '张三', '2022-01-15', '13800138001'),
(1002, '李四', '2022-03-20', '13800138002'),
(1003, '王五', '2022-05-10', '13800138003'),
(1004, '赵六', '2022-07-05', '13800138004');

INSERT INTO orders VALUES
(2001, 1001, '2023-06-10 14:30:00', 299.00, 'completed'),
(2002, 1001, '2023-07-15 10:15:00', 599.00, 'completed'),
(2003, 1002, '2023-08-05 16:45:00', 129.00, 'completed'),
(2004, 1003, '2023-09-20 11:20:00', 399.00, 'completed'),
(2005, 1003, '2023-10-01 09:30:00', 899.00, 'completed'),
(2006, 1004, '2023-10-15 13:10:00', 199.00, 'completed');
```

## 案例8：计算各月累计销售额
**业务场景**：财务部门需要分析销售业绩的月度趋势和累计完成情况。  
**SQL书写逻辑**：
1. 使用DATE_FORMAT将日期格式化为年月
2. 按月分组汇总销售额
3. 使用窗口函数SUM OVER计算累计销售额
4. 按月份排序输出结果

```sql
SELECT
    DATE_FORMAT(order_date, '%Y-%m') AS month,
    SUM(amount) AS monthly_sales,
    SUM(SUM(amount)) OVER (ORDER BY DATE_FORMAT(order_date, '%Y-%m')) AS cumulative_sales
FROM orders
WHERE order_date BETWEEN '2023-01-01' AND '2023-12-31'
GROUP BY DATE_FORMAT(order_date, '%Y-%m')
ORDER BY month;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE sales (
    sale_id INT PRIMARY KEY,
    product_id INT NOT NULL,
    sale_date DATE NOT NULL,
    amount DECIMAL(10,2) NOT NULL,
    quantity INT NOT NULL,
    region VARCHAR(20),
    INDEX idx_date (sale_date)
);

-- 示例数据
INSERT INTO sales VALUES
(1, 101, '2023-01-05', 1000.00, 10, 'North'),
(2, 102, '2023-01-15', 1500.00, 15, 'South'),
(3, 101, '2023-02-10', 800.00, 8, 'East'),
(4, 103, '2023-02-20', 1200.00, 12, 'West'),
(5, 102, '2023-03-08', 900.00, 9, 'North'),
(6, 101, '2023-03-18', 1100.00, 11, 'South'),
(7, 103, '2023-04-05', 700.00, 7, 'East'),
(8, 102, '2023-04-25', 1300.00, 13, 'West'),
(9, 101, '2023-05-12', 950.00, 9, 'North'),
(10, 103, '2023-05-22', 1050.00, 10, 'South');
```

## 案例9：识别异常订单（金额超过3个标准差）
**业务场景**：风控部门需要识别可能存在问题的异常交易订单。  
**SQL书写逻辑**：
1. 使用CTE计算订单金额的均值和标准差
2. 主查询计算每个订单的Z-score(与均值的差/标准差)
3. 筛选绝对值大于3的异常订单
4. 按Z-score绝对值降序排列

```sql
WITH order_stats AS (
    SELECT
        AVG(amount) AS avg_amount,
        STDDEV(amount) AS std_amount
    FROM sale_orders
    WHERE order_date BETWEEN '2023-01-01' AND '2023-12-31'
)
SELECT
    o.order_id,
    o.customer_id,
    o.amount,
    s.avg_amount,
    s.std_amount,
    (o.amount - s.avg_amount) / s.std_amount AS z_score
FROM sale_orders o
CROSS JOIN order_stats s
WHERE o.order_date BETWEEN '2023-01-01' AND '2023-12-31'
AND ABS((o.amount - s.avg_amount) / s.std_amount) > 1
ORDER BY ABS(z_score) DESC;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE sale_orders (
    order_id INT PRIMARY KEY,
    customer_id INT NOT NULL,
    order_date DATETIME NOT NULL,
    amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) NOT NULL,
    payment_method VARCHAR(20),
    INDEX idx_date_amount (order_date, amount)
);

-- 示例数据
INSERT INTO sale_orders VALUES
(1001, 2001, '2023-01-05 10:30:00', 299.00, 'completed', 'credit_card'),
(1002, 2002, '2023-01-10 14:15:00', 599.00, 'completed', 'paypal'),
(1003, 2003, '2023-01-15 11:20:00', 1299.00, 'completed', 'credit_card'),
(1004, 2001, '2023-01-20 09:45:00', 199.00, 'completed', 'alipay'),
(1005, 2004, '2023-01-25 16:30:00', 8999.00, 'completed', 'credit_card'),  -- 异常订单
(1006, 2005, '2023-01-30 13:10:00', 399.00, 'completed', 'wechat_pay'),
(1007, 2002, '2023-02-05 15:20:00', 599.00, 'completed', 'credit_card'),
(1008, 2003, '2023-02-10 10:15:00', 129.00, 'completed', 'alipay'),
(1009, 2006, '2023-02-15 12:30:00', 9999.00, 'completed', 'credit_card'),  -- 异常订单
(1010, 2001, '2023-02-20 14:45:00', 499.00, 'completed', 'paypal');
```

## 案例10：计算员工薪资等级分布
**业务场景**：企业管理层需要了解公司薪资结构分布情况。  
**SQL书写逻辑**：
1. 使用子查询将薪资划分为不同区间
2. 按薪资区间分组统计人数
3. 计算各区间人数占比
4. 按薪资区间排序输出结果

```sql
SELECT
    salary_range,
    COUNT(*) AS employee_count,
    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM tenant_employees), 2) AS percentage
FROM (
    SELECT
        CASE
            WHEN salary < 5000 THEN '0-5000'
            WHEN salary < 10000 THEN '5000-10000'
            WHEN salary < 15000 THEN '10000-15000'
            WHEN salary < 20000 THEN '15000-20000'
            ELSE '20000+'
        END AS salary_range
    FROM tenant_employees
) AS salary_groups
GROUP BY salary_range
ORDER BY salary_range;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE tenant_employees (
    employee_id INT PRIMARY KEY,
    employee_name VARCHAR(50) NOT NULL,
    department VARCHAR(30) NOT NULL,
    salary DECIMAL(10,2) NOT NULL,
    hire_date DATE NOT NULL,
    job_title VARCHAR(30),
    INDEX idx_salary (salary)
);

-- 示例数据
INSERT INTO tenant_employees VALUES
(1001, '张三', '研发部', 15000.00, '2020-06-15', '高级工程师'),
(1002, '李四', '研发部', 22000.00, '2018-03-10', '架构师'),
(1003, '王五', '市场部', 8500.00, '2021-01-20', '市场专员'),
(1004, '赵六', '市场部', 12000.00, '2019-11-05', '市场经理'),
(1005, '钱七', '财务部', 18000.00, '2017-07-22', '财务总监'),
(1006, '孙八', '人力资源部', 9500.00, '2020-09-30', 'HRBP'),
(1007, '周九', '研发部', 13000.00, '2021-05-18', '工程师'),
(1008, '吴十', '产品部', 16000.00, '2019-08-12', '产品经理'),
(1009, '郑十一', '财务部', 11000.00, '2020-02-28', '会计'),
(1010, '王十二', '人力资源部', 14000.00, '2018-12-10', 'HR经理');
```

## 案例11：计算班级连续3个月月考均前五的学生各科成绩
**业务场景**：学校需要识别稳定表现优异的学生，分析其各科成绩特点。  
**SQL书写逻辑**：
1. 使用CTE按月计算学生排名
2. 筛选连续3个月都在前5名的学生
3. 计算这些学生各科成绩的平均值、最小值和最大值
4. 按学生姓名和科目排序输出

```sql
WITH monthly_ranks AS (
    SELECT
        student_id,
        student_name,
        exam_month,
        subject,
        score,
        DENSE_RANK() OVER (PARTITION BY exam_month ORDER BY score DESC) AS month_rank
    FROM class_exam_results
    WHERE class_id = 'A101'
    AND exam_month BETWEEN '2023-09-01' AND '2023-11-01'
),
top_students AS (
    SELECT
        student_id,
        student_name
    FROM monthly_ranks
    WHERE month_rank <= 5
    GROUP BY student_id, student_name
    HAVING COUNT(DISTINCT exam_month) = 3  -- 连续3个月都出现
)
SELECT
    t.student_name,
    e.subject,
    AVG(e.score) AS avg_score,
    MIN(e.score) AS min_score,
    MAX(e.score) AS max_score
FROM top_students t
JOIN class_exam_results e ON t.student_id = e.student_id
WHERE e.exam_month BETWEEN '2023-09-01' AND '2023-11-01'
GROUP BY t.student_name, e.subject
ORDER BY t.student_name, e.subject;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE class_exam_results (
    id INT PRIMARY KEY AUTO_INCREMENT,
    student_id INT NOT NULL,
    student_name VARCHAR(50) NOT NULL,
    class_id VARCHAR(20) NOT NULL,
    subject VARCHAR(30) NOT NULL,
    score DECIMAL(5,2) NOT NULL,
    exam_month DATE NOT NULL,
    INDEX idx_class_subject_month (class_id, subject, exam_month),
    INDEX idx_student (student_id)
);

-- 示例数据
INSERT INTO class_exam_results (student_id, student_name, class_id, subject, score, exam_month) VALUES
(101, '张三', 'A101', '数学', 95.5, '2023-09-01'),
(101, '张三', 'A101', '语文', 88.0, '2023-09-01'),
(101, '张三', 'A101', '数学', 94.0, '2023-10-01'),
(101, '张三', 'A101', '语文', 89.5, '2023-10-01'),
(101, '张三', 'A101', '数学', 96.0, '2023-11-01'),
(101, '张三', 'A101', '语文', 91.0, '2023-11-01'),
(102, '李四', 'A101', '数学', 92.0, '2023-09-01'),
(102, '李四', 'A101', '语文', 85.5, '2023-09-01'),
(102, '李四', 'A101', '数学', 93.5, '2023-10-01'),
(102, '李四', 'A101', '语文', 87.0, '2023-10-01'),
(103, '王五', 'A101', '数学', 98.0, '2023-09-01'),
(103, '王五', 'A101', '语文', 90.0, '2023-09-01'),
(103, '王五', 'A101', '数学', 97.5, '2023-10-01'),
(103, '王五', 'A101', '语文', 92.0, '2023-10-01'),
(104, '赵六', 'A101', '数学', 89.0, '2023-09-01'),
(104, '赵六', 'A101', '语文', 92.5, '2023-09-01');
```

## 案例12：计算电商商品复购周期（平均购买间隔）
**业务场景**：电商运营需要分析不同商品的用户复购周期，优化库存和促销策略。  
**SQL书写逻辑**：
1. 使用LEAD函数获取同一用户对同一商品的下次购买日期
2. 计算两次购买的间隔天数
3. 按商品统计平均复购周期
4. 筛选至少有10次复购记录的商品
5. 按平均复购周期排序

```sql
WITH user_purchases AS (
    SELECT
        user_id,
        product_id,
        order_date,
        LEAD(order_date) OVER (PARTITION BY user_id, product_id ORDER BY order_date) AS next_purchase_date
    FROM product_orders
    WHERE order_date >= '2023-01-01'  -- 使用固定日期范围确保包含所有数据
),
repurchase_intervals AS (
    SELECT
        product_id,
        DATEDIFF(next_purchase_date, order_date) AS days_between_purchases
    FROM user_purchases
    WHERE next_purchase_date IS NOT NULL
)
SELECT
    p.product_id,
    p.product_name,
    AVG(r.days_between_purchases) AS avg_repurchase_days,
    COUNT(DISTINCT r.days_between_purchases) AS repurchase_count
FROM repurchase_intervals r
JOIN (
    SELECT DISTINCT product_id, product_name
    FROM product_orders
) p ON r.product_id = p.product_id
GROUP BY p.product_id, p.product_name
HAVING COUNT(DISTINCT r.days_between_purchases) >= 2
ORDER BY avg_repurchase_days;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE product_orders (
    order_id INT PRIMARY KEY,
    user_id INT NOT NULL,
    product_id INT NOT NULL,
    product_name VARCHAR(50) NOT NULL,
    order_date DATETIME NOT NULL,
    quantity INT NOT NULL,
    amount DECIMAL(10,2) NOT NULL,
    INDEX idx_user_product (user_id, product_id),
    INDEX idx_date (order_date)
);

-- 示例数据
INSERT INTO product_orders VALUES
(10001, 2001, 101, 'iPhone 13', '2023-01-05 10:30:00', 1, 5999.00),
(10002, 2001, 101, 'iPhone 13', '2023-04-15 14:20:00', 1, 5799.00),
(10003, 2001, 102, 'AirPods Pro', '2023-02-10 11:15:00', 1, 1499.00),
(10004, 2002, 101, 'iPhone 13', '2023-03-20 09:45:00', 1, 5899.00),
(10005, 2002, 102, 'AirPods Pro', '2023-03-20 09:45:00', 2, 1499.00),
(10006, 2002, 102, 'AirPods Pro', '2023-06-18 16:30:00', 1, 1399.00),
(10007, 2003, 103, 'MacBook Pro', '2023-05-12 13:10:00', 1, 12999.00),
(10008, 2004, 104, 'iPad Air', '2023-04-05 15:20:00', 1, 4399.00),
(10009, 2004, 104, 'iPad Air', '2023-07-25 10:15:00', 1, 4299.00),
(10010, 2004, 105, 'Apple Watch', '2023-06-30 12:30:00', 1, 2999.00),
(10011, 2001, 101, 'iPhone 13', '2023-07-10 10:30:00', 1, 5699.00),
(10012, 2002, 102, 'AirPods Pro', '2023-09-15 14:20:00', 1, 1299.00),
(10013, 2004, 104, 'iPad Air', '2023-10-05 11:15:00', 1, 4199.00);
```

## 案例13：识别信用卡异常消费模式
**业务场景**：银行风控系统需要实时识别可能存在盗刷风险的信用卡交易。  
**SQL书写逻辑**：
1. 计算每张卡的平均交易金额和标准差
2. 统计一周内的消费城市和国家数量
3. 定义异常类型判断规则
4. 筛选满足任一异常条件的交易
5. 关联客户信息输出结果

```sql
WITH transaction_stats AS (
    SELECT
        card_number,
        AVG(amount) AS avg_amount,
        STDDEV(amount) AS std_amount,
        COUNT(*) AS trans_count
    FROM credit_card_transactions
    WHERE transaction_date BETWEEN '2023-08-01' AND '2023-08-07' -- 固定日期范围
    GROUP BY card_number
),
location_stats AS (
    SELECT
        card_number,
        COUNT(DISTINCT city) AS city_count,
        COUNT(DISTINCT country) AS country_count
    FROM credit_card_transactions
    WHERE transaction_date BETWEEN '2023-08-01' AND '2023-08-07' -- 固定日期范围
    GROUP BY card_number
),
customer_info AS (
    SELECT DISTINCT
        card_number,
        customer_name
    FROM credit_card_transactions
)
SELECT
    t.card_number,
    c.customer_name,
    t.avg_amount,
    t.std_amount,
    l.city_count,
    l.country_count,
    CASE
        WHEN t.std_amount > t.avg_amount * 2 THEN '金额波动异常' -- 降低阈值
        WHEN l.city_count >= 3 THEN '多地消费异常' -- 改为>=3
        WHEN l.country_count > 1 THEN '跨国消费异常'
        ELSE '正常'
    END AS risk_type
FROM transaction_stats t
JOIN location_stats l ON t.card_number = l.card_number
JOIN customer_info c ON t.card_number = c.card_number
WHERE (t.std_amount > t.avg_amount * 2 OR l.city_count >= 3 OR l.country_count > 1);
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE credit_card_transactions (
    transaction_id INT PRIMARY KEY,
    card_number VARCHAR(20) NOT NULL,
    customer_name VARCHAR(50) NOT NULL,
    amount DECIMAL(10,2) NOT NULL,
    transaction_date DATETIME NOT NULL,
    merchant_name VARCHAR(50),
    city VARCHAR(30),
    country VARCHAR(30),
    INDEX idx_card_date (card_number, transaction_date),
    INDEX idx_amount (amount)
);

-- 示例数据
INSERT INTO credit_card_transactions VALUES
(1001, '622588******1234', '张三', 1500.00, '2023-08-01 10:30:00', '北京百货', '北京', '中国'),
(1002, '622588******1234', '张三', 80.50, '2023-08-03 12:15:00', '星巴克', '北京', '中国'),
(1003, '622588******1234', '张三', 3200.00, '2023-08-05 14:20:00', 'LV专卖店', '巴黎', '法国'),
(1004, '622588******1234', '张三', 45.00, '2023-08-07 18:30:00', '麦当劳', '伦敦', '英国'),
(1005, '622588******5678', '李四', 120.00, '2023-08-02 09:45:00', '超市发', '上海', '中国'),
(1006, '622588******5678', '李四', 680.00, '2023-08-04 11:20:00', '海底捞', '上海', '中国'),
(1007, '622588******5678', '李四', 150.00, '2023-08-06 13:10:00', '电影院', '上海', '中国'),
(1008, '622588******9012', '王五', 25000.00, '2023-08-01 16:45:00', '4S店', '广州', '中国'),
(1009, '622588******9012', '王五', 380.00, '2023-08-03 19:30:00', '酒店', '广州', '中国'),
(1010, '622588******9012', '王五', 95.00, '2023-08-05 21:15:00', '餐厅', '广州', '中国');
```

## 案例14：计算医院科室接诊效率（患者平均等待时间）
**业务场景**：医院管理部门需要分析各科室接诊效率，优化排班和资源配置。  
**SQL书写逻辑**：
1. 计算每位患者的等待时间(分钟)
2. 按科室、星期几和小时统计
3. 计算平均等待时间、中位数和最大值
4. 筛选至少有10条记录的统计结果
5. 按科室、星期几和小时排序

```sql
WITH patient_flows AS (
    SELECT
        department_id,
        patient_id,
        checkin_time,
        first_consultation_time,
        TIMESTAMPDIFF(MINUTE, checkin_time, first_consultation_time) AS wait_minutes,
        DAYOFWEEK(checkin_time) AS day_of_week,
        HOUR(checkin_time) AS hour_of_day
    FROM patient_records
    WHERE checkin_time BETWEEN '2023-09-01' AND '2023-09-30'  -- 使用固定日期范围
    AND first_consultation_time IS NOT NULL
),
ranked_data AS (
    SELECT
        d.department_name,
        p.wait_minutes,
        p.day_of_week,
        p.hour_of_day,
        COUNT(*) OVER (PARTITION BY d.department_name, p.day_of_week, p.hour_of_day) AS total_patients,
        ROW_NUMBER() OVER (PARTITION BY d.department_name, p.day_of_week, p.hour_of_day ORDER BY p.wait_minutes) AS row_num
    FROM patient_flows p
    JOIN hospital_departments d ON p.department_id = d.department_id
)
SELECT
    department_name,
    AVG(wait_minutes) AS avg_wait_time,
    MAX(CASE
        WHEN total_patients % 2 = 0 AND (row_num = total_patients/2 OR row_num = total_patients/2 + 1) THEN wait_minutes
        WHEN total_patients % 2 = 1 AND row_num = (total_patients + 1)/2 THEN wait_minutes
        ELSE NULL
    END) AS median_wait_time,
    MAX(wait_minutes) AS max_wait_time,
    day_of_week,
    hour_of_day,
    MAX(total_patients) AS patient_count
FROM ranked_data
GROUP BY department_name, day_of_week, hour_of_day
HAVING MAX(total_patients) >= 1  -- 降低阈值，因为数据量小
ORDER BY department_name, day_of_week, hour_of_day;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE hospital_departments (
    department_id INT PRIMARY KEY,
    department_name VARCHAR(50) NOT NULL,
    location VARCHAR(50)
);

-- 然后创建患者记录表，使用正确的外键引用
CREATE TABLE patient_records (
    record_id INT PRIMARY KEY,
    patient_id INT NOT NULL,
    patient_name VARCHAR(50) NOT NULL,
    department_id INT NOT NULL,
    checkin_time DATETIME NOT NULL,
    first_consultation_time DATETIME,
    diagnosis VARCHAR(100),
    FOREIGN KEY (department_id) REFERENCES hospital_departments(department_id),  -- 正确引用
    INDEX idx_dept_time (department_id, checkin_time)
);

-- 插入部门数据
INSERT INTO hospital_departments VALUES
(101, '内科', '1楼东区'),
(102, '外科', '1楼西区'),
(103, '儿科', '2楼东区'),
(104, '妇产科', '2楼西区');

-- 现在可以成功插入患者记录
INSERT INTO patient_records VALUES
(1001, 2001, '张三', 101, '2023-09-01 08:30:00', '2023-09-01 09:15:00', '感冒'),
(1002, 2002, '李四', 101, '2023-09-01 09:00:00', '2023-09-01 10:30:00', '高血压'),
(1003, 2003, '王五', 102, '2023-09-01 10:15:00', '2023-09-01 10:45:00', '骨折'),
(1004, 2004, '赵六', 102, '2023-09-01 11:00:00', '2023-09-01 12:30:00', '阑尾炎'),
(1005, 2005, '钱七', 103, '2023-09-01 13:30:00', '2023-09-01 14:00:00', '发热'),
(1006, 2006, '孙八', 103, '2023-09-01 14:15:00', '2023-09-01 15:45:00', '咳嗽'),
(1007, 2007, '周九', 104, '2023-09-01 15:30:00', '2023-09-01 16:15:00', '产检'),
(1008, 2008, '吴十', 104, '2023-09-01 16:00:00', '2023-09-01 17:30:00', '妇科检查'),
(1009, 2009, '郑十一', 101, '2023-09-02 08:30:00', '2023-09-02 09:45:00', '糖尿病'),
(1010, 2010, '王十二', 102, '2023-09-02 09:15:00', '2023-09-02 10:00:00', '外伤');
```

## 案例15：计算零售商品季节性销售指数
**业务场景**：零售企业需要分析商品销售的季节性规律，优化采购和促销计划。  
**SQL书写逻辑**：
1. 按月统计各商品销售额
2. 计算各商品月均销售额
3. 计算各月销售指数(月销售额/年均销售额)
4. 使用CASE WHEN转换为行转列格式
5. 按商品名称排序输出

```sql
WITH monthly_sales AS (
    SELECT
        product_id,
        DATE_FORMAT(sale_date, '%Y-%m') AS sale_month,
        SUM(sales_amount) AS monthly_sales
    FROM shop_sales
    WHERE sale_date BETWEEN '2020-01-01' AND '2023-12-31'
    GROUP BY product_id, DATE_FORMAT(sale_date, '%Y-%m')
),
product_avg AS (
    SELECT
        product_id,
        AVG(monthly_sales) AS avg_sales
    FROM monthly_sales
    GROUP BY product_id
),
monthly_index AS (
    SELECT
        m.product_id,
        p.product_name,
        SUBSTR(m.sale_month, 6, 2) AS month_num,
        AVG(m.monthly_sales / a.avg_sales) AS seasonal_index
    FROM monthly_sales m
    JOIN product_avg a ON m.product_id = a.product_id
    JOIN shop_products p ON m.product_id = p.product_id
    GROUP BY m.product_id, p.product_name, SUBSTR(m.sale_month, 6, 2)
)
SELECT
    product_id,
    product_name,
    MAX(CASE WHEN month_num = '01' THEN seasonal_index END) AS jan_index,
    MAX(CASE WHEN month_num = '02' THEN seasonal_index END) AS feb_index,
    -- ... 其他月份
    MAX(CASE WHEN month_num = '12' THEN seasonal_index END) AS dec_index
FROM monthly_index
GROUP BY product_id, product_name
ORDER BY product_name;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE shop_products (
    product_id INT PRIMARY KEY,
    product_name VARCHAR(50) NOT NULL,
    category VARCHAR(30) NOT NULL,
    price DECIMAL(10,2) NOT NULL
);

CREATE TABLE shop_sales (
    sale_id INT PRIMARY KEY,
    product_id INT NOT NULL,
    sale_date DATE NOT NULL,
    sales_amount DECIMAL(10,2) NOT NULL,
    quantity INT NOT NULL,
    store_id INT NOT NULL,
    FOREIGN KEY (product_id) REFERENCES shop_products(product_id),
    INDEX idx_date_product (sale_date, product_id)
);

-- 示例数据
INSERT INTO shop_products VALUES
(101, '羽绒服', '服装', 899.00),
(102, '空调', '家电', 2999.00),
(103, '防晒霜', '个护', 89.00),
(104, '游泳圈', '运动', 59.00),
(105, '月饼', '食品', 199.00);

INSERT INTO shop_sales VALUES
(1001, 101, '2022-01-15', 8990.00, 10, 1),
(1002, 101, '2022-12-20', 17980.00, 20, 1),
(1003, 102, '2022-06-10', 59980.00, 20, 2),
(1004, 102, '2022-07-15', 44985.00, 15, 2),
(1005, 103, '2022-05-01', 2670.00, 30, 3),
(1006, 103, '2022-06-10', 3560.00, 40, 3),
(1007, 104, '2022-07-05', 2950.00, 50, 4),
(1008, 104, '2022-08-12', 1770.00, 30, 4),
(1009, 105, '2022-09-10', 9950.00, 50, 5),
(1010, 105, '2023-09-01', 11970.00, 60, 5);

```

## 案例16：计算网约车司机接单效率（接单率/取消率）
**业务场景**：网约车平台需要评估司机服务质量，建立司机评级体系。  
**SQL书写逻辑**：
1. 统计司机7天内的订单情况
2. 计算完成订单数、司机取消数和乘客取消数
3. 计算接单率和各类取消率
4. 计算平均接单时间(分钟)
5. 按接单率降序和接单时间升序排列

```sql
WITH driver_orders AS (
    SELECT
        driver_id,
        COUNT(*) AS total_orders,
        SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) AS completed_orders,
        SUM(CASE WHEN status = 'cancelled_by_driver' THEN 1 ELSE 0 END) AS driver_cancels,
        SUM(CASE WHEN status = 'cancelled_by_passenger' THEN 1 ELSE 0 END) AS passenger_cancels,
        AVG(TIMESTAMPDIFF(SECOND, accept_time, pickup_time)) AS avg_pickup_seconds
    FROM ride_orders
    WHERE order_time BETWEEN '2023-10-01' AND '2023-10-07'  -- 使用固定日期范围
    GROUP BY driver_id
    HAVING COUNT(*) >= 2  -- 降低阈值
)
SELECT
    d.driver_id,
    d.driver_name,
    d.vehicle_type,
    o.total_orders,
    ROUND(o.completed_orders * 100.0 / o.total_orders, 2) AS completion_rate,
    ROUND(o.driver_cancels * 100.0 / o.total_orders, 2) AS driver_cancel_rate,
    ROUND(o.passenger_cancels * 100.0 / o.total_orders, 2) AS passenger_cancel_rate,
    ROUND(IFNULL(o.avg_pickup_seconds, 0) / 60, 2) AS avg_pickup_minutes
FROM driver_orders o
JOIN drivers d ON o.driver_id = d.driver_id
ORDER BY completion_rate DESC, avg_pickup_minutes ASC;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE drivers (
    driver_id INT PRIMARY KEY,
    driver_name VARCHAR(50) NOT NULL,
    vehicle_type VARCHAR(20) NOT NULL,
    register_date DATE NOT NULL,
    phone VARCHAR(20)
);

CREATE TABLE ride_orders (
    order_id INT PRIMARY KEY,
    driver_id INT NOT NULL,
    passenger_id INT NOT NULL,
    order_time DATETIME NOT NULL,
    accept_time DATETIME,
    pickup_time DATETIME,
    complete_time DATETIME,
    status VARCHAR(30) NOT NULL,
    fare DECIMAL(10,2) NOT NULL,
    distance DECIMAL(5,2) NOT NULL,
    FOREIGN KEY (driver_id) REFERENCES drivers(driver_id),
    INDEX idx_driver_status (driver_id, status),
    INDEX idx_order_time (order_time)
);

-- 示例数据
INSERT INTO drivers VALUES
(1001, '张三', '舒适型', '2022-01-15', '13800138001'),
(1002, '李四', '豪华型', '2022-03-20', '13800138002'),
(1003, '王五', '商务型', '2022-05-10', '13800138003'),
(1004, '赵六', '舒适型', '2022-07-05', '13800138004');

INSERT INTO ride_orders VALUES
(2001, 1001, 3001, '2023-10-01 08:30:00', '2023-10-01 08:32:00', '2023-10-01 08:40:00', '2023-10-01 09:00:00', 'completed', 45.00, 12.5),
(2002, 1001, 3002, '2023-10-01 10:15:00', '2023-10-01 10:16:00', '2023-10-01 10:25:00', '2023-10-01 10:50:00', 'completed', 38.00, 10.2),
(2003, 1001, 3003, '2023-10-02 14:30:00', '2023-10-02 14:35:00', NULL, NULL, 'cancelled_by_driver', 0.00, 0.0),
(2004, 1002, 3004, '2023-10-01 09:45:00', '2023-10-01 09:46:00', '2023-10-01 09:55:00', '2023-10-01 10:20:00', 'completed', 42.00, 11.8),
(2005, 1002, 3005, '2023-10-02 16:20:00', '2023-10-02 16:22:00', '2023-10-02 16:35:00', NULL, 'cancelled_by_passenger', 15.00, 3.5),
(2006, 1003, 3006, '2023-10-01 11:30:00', '2023-10-01 11:31:00', '2023-10-01 11:45:00', '2023-10-01 12:15:00', 'completed', 65.00, 18.0),
(2007, 1003, 3007, '2023-10-02 18:00:00', '2023-10-02 18:03:00', '2023-10-02 18:15:00', '2023-10-02 18:45:00', 'completed', 58.00, 16.2),
(2008, 1004, 3008, '2023-10-01 13:15:00', '2023-10-01 13:20:00', '2023-10-01 13:35:00', '2023-10-01 14:00:00', 'completed', 48.00, 13.5),
(2009, 1004, 3009, '2023-10-02 19:30:00', NULL, NULL, NULL, 'timeout', 0.00, 0.0),
(2010, 1004, 3010, '2023-10-03 07:45:00', '2023-10-03 07:47:00', '2023-10-03 08:00:00', '2023-10-03 08:30:00', 'completed', 52.00, 14.8);
```

## 案例17：计算广告渠道ROI（投入产出比）
**业务场景**：市场营销部门需要评估各广告渠道的投放效果，优化广告预算分配。  
**SQL书写逻辑**：
1. 统计各渠道10月的广告成本
2. 统计各渠道带来的新客户数和收入(含30天转化期)
3. 计算ROI(收入/成本)和获客成本(成本/新客户数)
4. 按ROI降序排列

```sql
WITH channel_costs AS (
    SELECT
        channel_id,
        SUM(cost_amount) AS total_cost
    FROM ad_campaigns
    WHERE campaign_date BETWEEN '2023-10-01' AND '2023-10-31'
    GROUP BY channel_id
),
channel_conversions AS (
    SELECT
        channel_id,
        COUNT(DISTINCT customer_id) AS converted_customers,
        SUM(CASE WHEN conversion_type = '购买' THEN 1 ELSE 0 END) AS purchase_conversions
    FROM ad_attributions
    WHERE attribution_date BETWEEN '2023-10-01' AND '2023-10-31'
    GROUP BY channel_id
)
SELECT
    c.channel_id,
    c.channel_name,
    c.channel_type,
    cc.total_cost,
    cv.converted_customers,
    cv.purchase_conversions,
    ROUND(cc.total_cost / NULLIF(cv.converted_customers, 0), 2) AS cost_per_acquisition,
    ROUND(cc.total_cost / NULLIF(cv.purchase_conversions, 0), 2) AS cost_per_purchase
FROM channels c
JOIN channel_costs cc ON c.channel_id = cc.channel_id
LEFT JOIN channel_conversions cv ON c.channel_id = cv.channel_id
ORDER BY cost_per_purchase ASC;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE channels (
    channel_id INT PRIMARY KEY,
    channel_name VARCHAR(50) NOT NULL,
    channel_type VARCHAR(30) NOT NULL
);

CREATE TABLE ad_campaigns (
    campaign_id INT PRIMARY KEY,
    channel_id INT NOT NULL,
    campaign_name VARCHAR(100) NOT NULL,
    campaign_date DATE NOT NULL,
    cost_amount DECIMAL(10,2) NOT NULL,
    impressions INT NOT NULL,
    clicks INT NOT NULL,
    FOREIGN KEY (channel_id) REFERENCES channels(channel_id),
    INDEX idx_channel_date (channel_id, campaign_date)
);

CREATE TABLE ad_attributions (
    attribution_id INT PRIMARY KEY,
    campaign_id INT NOT NULL,
    channel_id INT NOT NULL,
    customer_id INT NOT NULL,
    attribution_date DATETIME NOT NULL,
    conversion_type VARCHAR(30) NOT NULL,
    FOREIGN KEY (campaign_id) REFERENCES ad_campaigns(campaign_id),
    FOREIGN KEY (channel_id) REFERENCES channels(channel_id),
    INDEX idx_customer (customer_id)
);

-- 示例数据
INSERT INTO channels VALUES
(1, '百度搜索', '搜索引擎'),
(2, '微信朋友圈', '社交媒体'),
(3, '抖音信息流', '短视频'),
(4, '微博开屏', '社交媒体'),
(5, 'Google Ads', '搜索引擎');

INSERT INTO ad_campaigns VALUES
(101, 1, '国庆促销-百度', '2023-10-01', 50000.00, 1000000, 50000),
(102, 2, '国庆促销-微信', '2023-10-01', 80000.00, 2000000, 30000),
(103, 3, '国庆促销-抖音', '2023-10-01', 100000.00, 3000000, 100000),
(104, 4, '国庆促销-微博', '2023-10-01', 60000.00, 1500000, 40000),
(105, 5, '海外推广-Google', '2023-10-01', 30000.00, 500000, 20000);

INSERT INTO ad_attributions VALUES
(1001, 101, 1, 2001, '2023-10-01 10:30:00', '注册'),
(1002, 101, 1, 2002, '2023-10-01 11:15:00', '购买'),
(1003, 102, 2, 2003, '2023-10-02 09:45:00', '注册'),
(1004, 102, 2, 2004, '2023-10-02 14:20:00', '购买'),
(1005, 103, 3, 2005, '2023-10-01 16:30:00', '注册'),
(1006, 103, 3, 2006, '2023-10-03 10:15:00', '购买'),
(1007, 104, 4, 2007, '2023-10-02 11:45:00', '注册'),
(1008, 105, 5, 2008, '2023-10-01 13:20:00', '注册'),
(1009, 105, 5, 2009, '2023-10-04 15:30:00', '购买'),
(1010, 103, 3, 2010, '2023-10-05 09:15:00', '购买');
```

## 案例18：识别供应链异常交货（提前/延迟交货分析）
**业务场景**：采购部门需要评估供应商交货准时率，作为供应商考核的重要指标。  
**SQL书写逻辑**：
1. 计算实际交货日与承诺交货日的偏差天数
2. 标记提前、准时和延迟交货状态
3. 按供应商统计各类交货情况
4. 计算平均提前/延迟天数和延迟率
5. 按延迟率降序排列

```sql
WITH delivery_deviation AS (
    SELECT
        supplier_id,
        po_id,  -- 修正为正确的列名
        promised_delivery_date,
        actual_delivery_date,
        DATEDIFF(actual_delivery_date, promised_delivery_date) AS days_deviation,
        CASE
            WHEN actual_delivery_date < promised_delivery_date THEN 'early'
            WHEN actual_delivery_date > promised_delivery_date THEN 'late'
            ELSE 'on_time'
        END AS delivery_status
    FROM purchase_orders
    WHERE actual_delivery_date IS NOT NULL
    AND promised_delivery_date BETWEEN '2023-07-01' AND '2023-09-30'  -- 使用固定日期范围
),
supplier_stats AS (
    SELECT
        s.supplier_id,
        s.supplier_name,
        s.rating,
        COUNT(*) AS total_orders,
        SUM(CASE WHEN d.delivery_status = 'early' THEN 1 ELSE 0 END) AS early_deliveries,
        SUM(CASE WHEN d.delivery_status = 'late' THEN 1 ELSE 0 END) AS late_deliveries,
        SUM(CASE WHEN d.delivery_status = 'on_time' THEN 1 ELSE 0 END) AS on_time_deliveries,
        ROUND(AVG(CASE WHEN d.delivery_status = 'early' THEN d.days_deviation ELSE NULL END), 2) AS avg_early_days,
        ROUND(AVG(CASE WHEN d.delivery_status = 'late' THEN d.days_deviation ELSE NULL END), 2) AS avg_late_days,
        ROUND(SUM(CASE WHEN d.delivery_status = 'late' THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS late_percentage
    FROM delivery_deviation d
    JOIN suppliers s ON d.supplier_id = s.supplier_id
    GROUP BY s.supplier_id, s.supplier_name, s.rating
)
SELECT
    supplier_id,
    supplier_name,
    rating,
    total_orders,
    early_deliveries,
    late_deliveries,
    on_time_deliveries,
    avg_early_days,
    avg_late_days,
    late_percentage,
    CASE
        WHEN late_percentage < 10 THEN '优秀'
        WHEN late_percentage < 30 THEN '良好'
        WHEN late_percentage < 50 THEN '一般'
        ELSE '差'
    END AS performance_rating
FROM supplier_stats
ORDER BY late_percentage DESC, rating DESC;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE suppliers (
    supplier_id INT PRIMARY KEY,
    supplier_name VARCHAR(50) NOT NULL,
    contact_person VARCHAR(30),
    phone VARCHAR(20),
    rating DECIMAL(3,1)
);

CREATE TABLE purchase_orders (
    po_id INT PRIMARY KEY,
    supplier_id INT NOT NULL,
    order_date DATE NOT NULL,
    promised_delivery_date DATE NOT NULL,
    actual_delivery_date DATE,
    total_amount DECIMAL(12,2) NOT NULL,
    status VARCHAR(20) NOT NULL,
    FOREIGN KEY (supplier_id) REFERENCES suppliers(supplier_id),
    INDEX idx_supplier_dates (supplier_id, promised_delivery_date, actual_delivery_date)
);

-- 示例数据
INSERT INTO suppliers VALUES
(1001, 'ABC电子', '张经理', '13800138001', 4.5),
(1002, 'XYZ五金', '李主管', '13800138002', 3.8),
(1003, 'DEF包装', '王总监', '13800138003', 4.2),
(1004, 'GHI化工', '赵经理', '13800138004', 4.0),
(1005, 'JKL机械', '钱总', '13800138005', 4.7);

INSERT INTO purchase_orders VALUES
(2001, 1001, '2023-07-01', '2023-07-15', '2023-07-10', 50000.00, 'completed'),
(2002, 1001, '2023-07-10', '2023-07-25', '2023-07-30', 75000.00, 'completed'),
(2003, 1002, '2023-07-05', '2023-07-20', '2023-07-18', 30000.00, 'completed'),
(2004, 1002, '2023-07-15', '2023-07-30', '2023-08-05', 45000.00, 'completed'),
(2005, 1003, '2023-07-20', '2023-08-05', '2023-08-01', 60000.00, 'completed'),
(2006, 1003, '2023-08-01', '2023-08-15', '2023-08-10', 55000.00, 'completed'),
(2007, 1004, '2023-08-05', '2023-08-20', '2023-08-25', 35000.00, 'completed'),
(2008, 1004, '2023-08-10', '2023-08-25', '2023-08-20', 40000.00, 'completed'),
(2009, 1005, '2023-08-15', '2023-09-01', '2023-08-28', 80000.00, 'completed'),
(2010, 1005, '2023-09-01', '2023-09-15', '2023-09-10', 70000.00, 'completed');

```

## 案例19：计算客户生命周期价值（LTV）
**业务场景**：电商企业需要分析不同时期获取的客户价值，评估获客成本合理性。  
**SQL书写逻辑**：
1. 找出每个客户的首次购买日期
2. 计算客户获取后的月数
3. 按3个月为周期分组统计
4. 计算每组的平均收入、订单数和客户数
5. 推算年化LTV

```sql
WITH first_purchases AS (
    SELECT
        customer_id,
        MIN(order_date) AS first_order_date
    FROM customer_orders
    GROUP BY customer_id
),
customer_months AS (
    SELECT
        c.customer_id,
        TIMESTAMPDIFF(MONTH, fp.first_order_date, CURRENT_DATE) AS months_since_first_order
    FROM customers c
    JOIN first_purchases fp ON c.customer_id = fp.customer_id
    WHERE fp.first_order_date >= DATE_SUB(CURRENT_DATE, INTERVAL 3 YEAR)
),
customer_revenues AS (
    SELECT
        co.customer_id,
        cm.months_since_first_order,
        SUM(co.amount) AS total_revenue,
        COUNT(DISTINCT co.order_id) AS order_count
    FROM customer_orders co
    JOIN customer_months cm ON co.customer_id = cm.customer_id
    GROUP BY co.customer_id, cm.months_since_first_order
),
cohort_analysis AS (
    SELECT
        FLOOR(months_since_first_order / 3) * 3 AS cohort_month,
        AVG(total_revenue) AS avg_revenue,
        AVG(order_count) AS avg_orders,
        COUNT(DISTINCT customer_id) AS customer_count
    FROM customer_revenues
    GROUP BY FLOOR(months_since_first_order / 3) * 3
)
SELECT
    cohort_month,
    cohort_month + 3 AS next_cohort,
    customer_count,
    ROUND(avg_revenue, 2) AS avg_revenue,
    ROUND(avg_orders, 2) AS avg_orders,
    ROUND(avg_revenue / NULLIF(avg_orders, 0), 2) AS avg_order_value,
    ROUND(avg_revenue * 12 / NULLIF(cohort_month + 1, 0), 2) AS projected_annual_ltv
FROM cohort_analysis
ORDER BY cohort_month;
```


**DDL语句和示例数据**
```sql
CREATE TABLE customers (
    customer_id INT PRIMARY KEY,
    customer_name VARCHAR(50) NOT NULL,
    register_date DATE NOT NULL,
    channel VARCHAR(30) NOT NULL,
    tier VARCHAR(20) NOT NULL
);

CREATE TABLE customer_orders (
    order_id INT PRIMARY KEY,
    customer_id INT NOT NULL,
    order_date DATETIME NOT NULL,
    amount DECIMAL(10,2) NOT NULL,
    payment_method VARCHAR(20) NOT NULL,
    status VARCHAR(20) NOT NULL,
    FOREIGN KEY (customer_id) REFERENCES customers(customer_id),
    INDEX idx_customer_date (customer_id, order_date)
);

-- 示例数据
INSERT INTO customers VALUES
(1001, '张三', '2022-01-15', '自然流量', '普通'),
(1002, '李四', '2022-03-20', '广告投放', '白银'),
(1003, '王五', '2022-05-10', '推荐注册', '黄金'),
(1004, '赵六', '2022-07-05', '活动引流', '普通'),
(1005, '钱七', '2022-09-30', '广告投放', '白银'),
(1006, '孙八', '2023-01-15', '自然流量', '普通'),
(1007, '周九', '2023-03-20', '推荐注册', '黄金'),
(1008, '吴十', '2023-05-10', '广告投放', '白银'),
(1009, '郑十一', '2023-07-05', '活动引流', '普通'),
(1010, '王十二', '2023-09-30', '自然流量', '普通');

INSERT INTO customer_orders VALUES
(2001, 1001, '2022-01-20 10:30:00', 299.00, '支付宝', 'completed'),
(2002, 1001, '2022-02-15 14:20:00', 599.00, '微信支付', 'completed'),
(2003, 1001, '2022-05-10 11:15:00', 1299.00, '信用卡', 'completed'),
(2004, 1002, '2022-04-05 09:45:00', 199.00, '支付宝', 'completed'),
(2005, 1002, '2022-06-20 16:30:00', 899.00, '微信支付', 'completed'),
(2006, 1003, '2022-06-12 13:10:00', 399.00, '信用卡', 'completed'),
(2007, 1003, '2022-08-25 15:20:00', 599.00, '支付宝', 'completed'),
(2008, 1004, '2022-08-10 10:15:00', 129.00, '微信支付', 'completed'),
(2009, 1005, '2022-10-15 12:30:00', 999.00, '信用卡', 'completed'),
(2010, 1005, '2023-01-20 14:45:00', 499.00, '支付宝', 'completed');
```

## 案例20：智能推荐系统候选商品筛选
**业务场景**：电商平台需要基于用户行为数据，为每个用户生成个性化商品推荐列表。  
**SQL书写逻辑**：
1. 统计用户30天内的商品交互行为
2. 找出有相似购买行为的用户
3. 计算推荐分数(相似用户购买次数加权)
4. 排除用户已交互过的商品
5. 按推荐分数降序输出结果

```sql
WITH user_behavior AS (
    SELECT
        user_id,
        product_id,
        SUM(CASE WHEN behavior_type = 'view' THEN 1 ELSE 0 END) AS view_count,
        SUM(CASE WHEN behavior_type = 'cart' THEN 1 ELSE 0 END) AS cart_count,
        SUM(CASE WHEN behavior_type = 'purchase' THEN 1 ELSE 0 END) AS purchase_count,
        MAX(event_time) AS last_interaction_time
    FROM user_behaviors
    WHERE event_time BETWEEN '2023-06-01' AND '2023-06-30'
    GROUP BY user_id, product_id
),
similar_users AS (
    SELECT
        u1.user_id AS target_user,
        u2.user_id AS similar_user,
        COUNT(DISTINCT CASE WHEN u1.product_id = u2.product_id THEN u2.product_id END) AS common_products,
        ROW_NUMBER() OVER (PARTITION BY u1.user_id ORDER BY COUNT(DISTINCT CASE WHEN u1.product_id = u2.product_id THEN u2.product_id END) DESC) AS similarity_rank
    FROM user_behavior u1
    JOIN user_behavior u2 ON u1.user_id != u2.user_id
    GROUP BY u1.user_id, u2.user_id
),
recommendation_candidates AS (
    SELECT
        s.target_user,
        b.product_id,
        p.product_name,
        p.category,
        SUM(b.view_count + b.cart_count * 2 + b.purchase_count * 3) AS recommendation_score,
        MAX(b.last_interaction_time) AS last_interaction
    FROM similar_users s
    JOIN user_behavior b ON s.similar_user = b.user_id
    JOIN products p ON b.product_id = p.product_id
    LEFT JOIN user_behavior ub ON s.target_user = ub.user_id AND b.product_id = ub.product_id
    WHERE ub.product_id IS NULL
    AND s.similarity_rank <= 3  -- 只考虑前3个相似用户
    GROUP BY s.target_user, b.product_id, p.product_name, p.category
    HAVING SUM(b.view_count + b.cart_count * 2 + b.purchase_count * 3) > 0
)
SELECT
    target_user AS "用户ID",
    product_id AS "商品ID",
    product_name AS "商品名称",
    category AS "商品类别",
    recommendation_score AS "推荐分数"
FROM recommendation_candidates
ORDER BY target_user, recommendation_score DESC
LIMIT 1000;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE user_behaviors (
    user_id INT,
    product_id INT,
    behavior_type VARCHAR(20),
    event_time DATETIME
);

CREATE TABLE products (
    product_id INT PRIMARY KEY,
    product_name VARCHAR(100),
    category VARCHAR(50)
);

-- 示例数据
INSERT INTO user_behaviors VALUES
(1, 101, 'view', '2023-06-01 10:00:00'),
(1, 101, 'cart', '2023-06-02 11:00:00'),
(1, 102, 'view', '2023-06-03 12:00:00'),
(1, 103, 'purchase', '2023-06-05 14:00:00'),
(2, 101, 'view', '2023-06-01 15:00:00'),
(2, 101, 'purchase', '2023-06-02 16:00:00'),
(2, 104, 'view', '2023-06-04 17:00:00'),
(3, 102, 'purchase', '2023-06-03 18:00:00'),
(3, 105, 'view', '2023-06-05 19:00:00');

INSERT INTO products VALUES
(101, '智能手机', '电子产品'),
(102, '无线耳机', '电子产品'),
(103, '运动鞋', '服饰'),
(104, '背包', '箱包'),
(105, '智能手表', '电子产品');

```

## 案例21：计算用户购买路径转化漏斗
**业务场景**：电商平台需要分析用户从浏览到最终购买的转化路径，优化关键环节的转化率。  
**SQL书写逻辑**：
1. 统计用户各类行为(浏览、加购、结算、购买)的次数
2. 计算各环节用户总数
3. 计算环节间转化率
4. 保留两位小数输出结果

```sql
WITH user_journey AS (
    SELECT 
        user_id,
        SUM(CASE WHEN event_type = 'view' THEN 1 ELSE 0 END) AS view_count,
        SUM(CASE WHEN event_type = 'cart' THEN 1 ELSE 0 END) AS cart_count,
        SUM(CASE WHEN event_type = 'checkout' THEN 1 ELSE 0 END) AS checkout_count,
        SUM(CASE WHEN event_type = 'purchase' THEN 1 ELSE 0 END) AS purchase_count
    FROM user_events
    WHERE event_date BETWEEN '2023-01-01' AND '2023-12-31'
    GROUP BY user_id
)
SELECT 
    COUNT(*) AS total_users,
    SUM(view_count) AS total_views,
    SUM(cart_count) AS total_carts,
    SUM(checkout_count) AS total_checkouts,
    SUM(purchase_count) AS total_purchases,
    ROUND(SUM(cart_count) * 100.0 / SUM(view_count), 2) AS view_to_cart_rate,
    ROUND(SUM(checkout_count) * 100.0 / SUM(cart_count), 2) AS cart_to_checkout_rate,
    ROUND(SUM(purchase_count) * 100.0 / SUM(checkout_count), 2) AS checkout_to_purchase_rate
FROM user_journey;
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE user_events (
    user_id INT,
    event_type VARCHAR(20),
    event_date DATE
);

-- 示例数据
INSERT INTO user_events VALUES
(1, 'view', '2023-01-01'),
(1, 'view', '2023-01-02'),
(1, 'cart', '2023-01-03'),
(1, 'checkout', '2023-01-04'),
(1, 'purchase', '2023-01-05'),
(2, 'view', '2023-02-01'),
(2, 'view', '2023-02-02'),
(2, 'cart', '2023-02-03'),
(3, 'view', '2023-03-01'),
(3, 'view', '2023-03-02'),
(3, 'view', '2023-03-03'),
(4, 'view', '2023-04-01'),
(4, 'cart', '2023-04-02'),
(4, 'checkout', '2023-04-03'),
(4, 'purchase', '2023-04-04'),
(5, 'view', '2023-05-01');
```

## 案例22：计算用户RFM模型（最近购买时间、购买频次、消费金额）
**业务场景**：零售企业需要基于RFM模型对客户进行分层，制定精准营销策略。  
**SQL书写逻辑**：
1. 计算每个客户的R(最近购买时间)、F(购买频次)、M(消费金额)
2. 使用NTILE函数将每个维度分为5分
3. 组合RFM分数形成客户细分
4. 根据RFM分数定义客户类型
5. 按R、F、M分数降序排列

```sql
WITH rfm_data AS (
    SELECT
        customer_id,
        DATEDIFF('2023-06-30', MAX(order_date)) AS recency,  -- 计算到2023-06-30的间隔天数
        COUNT(DISTINCT order_id) AS frequency,
        SUM(amount) AS monetary
    FROM shop_orders
    WHERE order_date BETWEEN '2022-07-01' AND '2023-06-30'  -- 固定1年时间范围
    GROUP BY customer_id
),
rfm_scores AS (
    SELECT
        customer_id,
        recency,
        frequency,
        monetary,
        NTILE(5) OVER (ORDER BY recency DESC) AS r_score,  -- 最近购买得高分
        NTILE(5) OVER (ORDER BY frequency) AS f_score,      -- 购买频率高得高分
        NTILE(5) OVER (ORDER BY monetary) AS m_score        -- 消费金额高得高分
    FROM rfm_data
)
SELECT
    customer_id AS "客户ID",
    recency AS "最近购买天数",
    frequency AS "购买频次",
    monetary AS "消费金额",
    r_score AS "R得分",
    f_score AS "F得分",
    m_score AS "M得分",
    CONCAT(r_score, f_score, m_score) AS "RFM细分",
    CASE
        WHEN r_score >= 4 AND f_score >= 4 AND m_score >= 4 THEN '高价值客户'
        WHEN r_score >= 3 AND f_score >= 3 AND m_score >= 3 THEN '潜力客户'
        WHEN r_score <= 2 AND f_score <= 2 AND m_score <= 2 THEN '流失风险客户'
        ELSE '一般客户'
    END AS "客户细分"
FROM rfm_scores
ORDER BY r_score DESC, f_score DESC, m_score DESC;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE shop_orders (
    customer_id INT,
    order_id INT PRIMARY KEY,
    order_date DATE,
    amount DECIMAL(10,2)
);

-- 示例数据
INSERT INTO shop_orders VALUES
(1, 1001, '2023-06-01', 150.00),
(1, 1002, '2023-05-15', 200.00),
(1, 1003, '2023-04-10', 100.00),
(2, 1004, '2023-06-05', 300.00),
(2, 1005, '2023-03-20', 250.00),
(3, 1006, '2023-05-20', 180.00),
(3, 1007, '2023-05-25', 220.00),
(3, 1008, '2023-06-10', 190.00),
(4, 1009, '2023-01-15', 500.00),
(5, 1010, '2023-06-12', 120.00);
```

## 案例23：计算A/B测试结果统计显著性
**业务场景**：产品运营团队需要评估A/B测试结果的统计显著性，判断新策略是否有效。  
**SQL书写逻辑**：
1. 统计测试组和对照组的用户数、转化数和收入
2. 计算转化率和ARPU
3. 计算Z-score评估差异显著性
4. 判断结果是否显著(p<0.05)
5. 输出两组对比结果

```sql
WITH ab_test_results AS (
    SELECT
        test_group,
        COUNT(DISTINCT user_id) AS user_count,
        SUM(CASE WHEN converted THEN 1 ELSE 0 END) AS conversions,
        SUM(revenue) AS total_revenue
    FROM ab_test_data
    WHERE test_id = '2023_promotion_test'
    GROUP BY test_group
),
ab_stats AS (
    SELECT
        test_group,
        user_count,
        conversions,
        total_revenue,
        conversions / user_count AS conversion_rate,
        total_revenue / user_count AS arpu
    FROM ab_test_results
),
combined_stats AS (
    SELECT
        SUM(user_count) AS total_users,
        SUM(conversions) AS total_conversions,
        SUM(total_revenue) AS total_revenue
    FROM ab_test_results
)
SELECT
    a.test_group AS "测试组",
    a.user_count AS "用户数",
    a.conversions AS "转化数",
    ROUND(a.conversion_rate, 4) AS "转化率",
    ROUND(a.arpu, 2) AS "每用户平均收入(ARPU)",
    ROUND((a.conversion_rate - b.conversion_rate) / SQRT(
        (a.conversion_rate * (1 - a.conversion_rate) / a.user_count) +
        (b.conversion_rate * (1 - b.conversion_rate) / b.user_count)
    ), 4) AS "Z分数",
    CASE
        WHEN ABS((a.conversion_rate - b.conversion_rate) / SQRT(
            (a.conversion_rate * (1 - a.conversion_rate) / a.user_count) +
            (b.conversion_rate * (1 - b.conversion_rate) / b.user_count)
        )) > 1.96 THEN '显著差异 (p < 0.05)'
        ELSE '无显著差异'
    END AS "显著性"
FROM ab_stats a
CROSS JOIN ab_stats b
WHERE a.test_group = 'A' AND b.test_group = 'B';
```


**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE ab_test_data (
    test_id VARCHAR(50),
    user_id INT,
    test_group VARCHAR(10),
    converted BOOLEAN,
    revenue DECIMAL(10,2)
);

-- 示例数据
INSERT INTO ab_test_data VALUES
('2023_promotion_test', 1, 'A', TRUE, 100.00),
('2023_promotion_test', 2, 'A', TRUE, 150.00),
('2023_promotion_test', 3, 'A', FALSE, 0.00),
('2023_promotion_test', 4, 'A', TRUE, 200.00),
('2023_promotion_test', 5, 'A', FALSE, 0.00),
('2023_promotion_test', 6, 'B', TRUE, 120.00),
('2023_promotion_test', 7, 'B', FALSE, 0.00),
('2023_promotion_test', 8, 'B', FALSE, 0.00),
('2023_promotion_test', 9, 'B', TRUE, 180.00),
('2023_promotion_test', 10, 'B', FALSE, 0.00);
```

## 案例24：计算股票价格波动率（滚动标准差）
**业务场景**：金融投资机构需要计算股票价格的滚动波动率，评估投资风险。  
**SQL书写逻辑**：
1. 计算股票日收益率
2. 计算20日滚动标准差
3. 年化波动率(乘以√252)
4. 根据波动率大小标记风险等级
5. 按股票代码和交易日期排序

```sql
WITH stock_daily_returns AS (
    SELECT
        stock_code,
        trade_date,
        close_price,
        (close_price - LAG(close_price) OVER (PARTITION BY stock_code ORDER BY trade_date)) /
        LAG(close_price) OVER (PARTITION BY stock_code ORDER BY trade_date) AS daily_return
    FROM stock_prices
    WHERE trade_date BETWEEN '2023-05-01' AND '2023-05-10'  -- 使用固定日期范围
),
rolling_volatility AS (
    SELECT
        stock_code,
        trade_date,
        close_price,
        STDDEV(daily_return) OVER (
            PARTITION BY stock_code
            ORDER BY trade_date
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW  -- 改为3天窗口，因为数据量小
        ) * SQRT(252) AS annualized_volatility  -- 252个交易日
    FROM stock_daily_returns
)
SELECT
    stock_code AS "股票代码",
    trade_date AS "交易日期",
    close_price AS "收盘价",
    ROUND(annualized_volatility, 4) AS "年化波动率",
    CASE
        WHEN annualized_volatility > 0.3 THEN '高风险'
        WHEN annualized_volatility > 0.15 THEN '中风险'
        ELSE '低风险'
    END AS "风险等级"
FROM rolling_volatility
ORDER BY stock_code, trade_date;
```



**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE stock_prices (
    stock_code VARCHAR(10),
    trade_date DATE,
    close_price DECIMAL(10,2)
);

-- 示例数据
INSERT INTO stock_prices VALUES
('AAPL', '2023-05-01', 170.00),
('AAPL', '2023-05-02', 172.50),
('AAPL', '2023-05-03', 171.25),
('AAPL', '2023-05-04', 173.75),
('AAPL', '2023-05-05', 175.00),
('AAPL', '2023-05-08', 174.50),
('AAPL', '2023-05-09', 176.25),
('AAPL', '2023-05-10', 177.00),
('GOOGL', '2023-05-01', 120.00),
('GOOGL', '2023-05-02', 121.50),
('GOOGL', '2023-05-03', 119.75),
('GOOGL', '2023-05-04', 122.25),
('GOOGL', '2023-05-05', 123.00),
('GOOGL', '2023-05-08', 121.50),
('GOOGL', '2023-05-09', 124.00),
('GOOGL', '2023-05-10', 125.50);
```

## 案例25：计算社交媒体用户互动网络（共同关注关系）
**业务场景**：社交平台需要分析用户之间的互动关系，识别高影响力用户群体。  
**SQL书写逻辑**：
1. 找出用户间的共同关注关系
2. 统计用户间的互动行为(点赞)
3. 计算互动率和总互动次数
4. 筛选至少有3个共同关注的用户对
5. 按共同关注数和互动次数降序排列

```sql
WITH user_follows AS (
    SELECT
        follower_id AS user_id,
        followee_id AS follows
    FROM social_connections
),
common_follows AS (
    SELECT
        a.user_id AS user1,
        b.user_id AS user2,
        COUNT(DISTINCT a.follows) AS common_follow_count
    FROM user_follows a
    JOIN user_follows b ON a.follows = b.follows AND a.user_id < b.user_id
    GROUP BY a.user_id, b.user_id
    HAVING COUNT(DISTINCT a.follows) >= 1  -- 降低共同关注阈值
),
user_interactions AS (
    SELECT
        cf.user1,
        cf.user2,
        cf.common_follow_count,
        (SELECT COUNT(*) FROM social_posts p WHERE p.user_id = cf.user1 OR p.user_id = cf.user2) AS total_posts,
        (SELECT COUNT(*) FROM social_likes l WHERE l.user_id = cf.user1 AND l.post_id IN
            (SELECT post_id FROM social_posts WHERE user_id = cf.user2)) AS likes_from_user1_to_user2,
        (SELECT COUNT(*) FROM social_likes l WHERE l.user_id = cf.user2 AND l.post_id IN
            (SELECT post_id FROM social_posts WHERE user_id = cf.user1)) AS likes_from_user2_to_user1
    FROM common_follows cf
)
SELECT
    u1.username AS user1_name,
    u2.username AS user2_name,
    ui.common_follow_count,
    ui.likes_from_user1_to_user2 + ui.likes_from_user2_to_user1 AS total_interactions,
    CASE 
        WHEN ui.total_posts = 0 THEN 0
        ELSE ROUND((ui.likes_from_user1_to_user2 + ui.likes_from_user2_to_user1) * 100.0 / ui.total_posts, 2)
    END AS interaction_rate
FROM user_interactions ui
JOIN mobile_users u1 ON ui.user1 = u1.user_id
JOIN mobile_users u2 ON ui.user2 = u2.user_id
ORDER BY ui.common_follow_count DESC, total_interactions DESC
LIMIT 100;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE social_connections (
    follower_id INT,
    followee_id INT
);

CREATE TABLE social_posts (
    post_id INT PRIMARY KEY,
    user_id INT,
    content TEXT
);

CREATE TABLE social_likes (
    user_id INT,
    post_id INT
);

CREATE TABLE mobile_users (
    user_id INT PRIMARY KEY,
    username VARCHAR(50)
);

-- 示例数据
INSERT INTO social_connections VALUES
(1, 3), (1, 4), (1, 5),
(2, 3), (2, 4), (2, 6),
(3, 1), (3, 2), (3, 5),
(4, 1), (4, 2), (4, 3),
(5, 1), (5, 3), (5, 6),
(6, 2), (6, 4), (6, 5);

INSERT INTO social_posts VALUES
(1, 1, '今天天气真好'),
(2, 1, '分享一张照片'),
(3, 2, '新买的手机'),
(4, 2, '周末去哪里玩'),
(5, 3, '美食推荐'),
(6, 3, '旅游日记'),
(7, 4, '健身打卡'),
(8, 5, '读书笔记');

INSERT INTO social_likes VALUES
(2, 1), (3, 1), (4, 1),
(1, 3), (3, 3), (5, 3),
(2, 5), (4, 5), (6, 5),
(1, 7), (3, 7), (5, 7);

INSERT INTO mobile_users VALUES
(1, '张三'), (2, '李四'), (3, '王五'),
(4, '赵六'), (5, '钱七'), (6, '孙八');
```

## 案例26：多维主外键一致性与孤儿数据批量修复建议  
**业务场景**：大型集团的订单、客户、商品三表存在主外键关联，需批量检测并修复所有孤儿订单（无客户或无商品），并输出修复建议（如自动分配默认客户/商品或标记为异常）。  
**SQL逻辑**：  
1. LEFT JOIN订单表与客户表、商品表  
2. 检查客户或商品缺失  
3. 输出孤儿订单及修复建议

```sql
SELECT 
    o.order_id,
    o.customer_id,
    o.product_id,
    CASE 
        WHEN c.customer_id IS NULL AND p.product_id IS NULL THEN '客户和商品均缺失'
        WHEN c.customer_id IS NULL THEN '客户缺失'
        WHEN p.product_id IS NULL THEN '商品缺失'
        ELSE '正常'
    END AS anomaly_type,
    CASE 
        WHEN c.customer_id IS NULL AND p.product_id IS NULL THEN '建议分配默认客户和商品'
        WHEN c.customer_id IS NULL THEN '建议分配默认客户'
        WHEN p.product_id IS NULL THEN '建议分配默认商品'
        ELSE '无需处理'
    END AS fix_suggestion
FROM orders_26 o
LEFT JOIN customers_26 c ON o.customer_id = c.customer_id
LEFT JOIN products_26 p ON o.product_id = p.product_id
WHERE c.customer_id IS NULL OR p.product_id IS NULL;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE if not exists customers_26 (
    customer_id INT,
    customer_name VARCHAR(50)
);

CREATE TABLE if not exists products_26 (
    product_id INT,
    product_name VARCHAR(50)
);

CREATE TABLE if not exists orders_26 (
    order_id INT,
    customer_id INT,
    product_id INT,
    order_date DATE
);

-- 示例数据
INSERT INTO customers_26 VALUES (1, '客户A'), (2, '客户B'), (3, '客户C'), (4, '客户D'), (5, '客户E');
INSERT INTO products_26 VALUES (10, '商品X'), (20, '商品Y'), (30, '商品Z'), (40, '商品W'), (50, '商品V');
INSERT INTO orders_26 VALUES
  (1001, 1, 10, '2024-07-01'),
  (1002, 2, 20, '2024-07-02'),
  (1003, 3, 10, '2024-07-03'),
  (1004, 1, 30, '2024-07-04'),
  (1005, 4, 40, '2024-07-05'),
  (1006, 5, 50, '2024-07-06'),
  (1007, 6, 60, '2024-07-07'); -- 存在缺失客户/商品的情况
``` 

## 案例27：跨部门多表数据口径一致性校验与差异定位  
**业务场景**：财务、销售、仓储三部门各自维护订单金额、发货数量、入库数量，需校验同一订单在三部门数据口径是否一致，并定位差异来源。  
**SQL逻辑**：  
1. 多表JOIN订单、发货、入库  
2. 比较金额、数量  
3. 输出差异类型及定位建议

```sql
SELECT
    o.order_id,
    o.amount AS sales_amount,
    d.amount AS delivery_amount,
    w.amount AS warehouse_amount,
    CASE
        WHEN o.amount != d.amount AND o.amount != w.amount THEN '销售与发货、仓库均不一致'
        WHEN o.amount != d.amount THEN '销售与发货不一致'
        WHEN o.amount != w.amount THEN '销售与仓库不一致'
        ELSE '一致'
    END AS diff_type,
    CASE
        WHEN o.amount != d.amount THEN '建议核查销售与发货数据'
        WHEN o.amount != w.amount THEN '建议核查销售与仓库数据'
        ELSE '无需处理'
    END AS fix_suggestion
FROM sales_orders_27 o
LEFT JOIN delivery_orders_27 d ON o.order_id = d.order_id
LEFT JOIN warehouse_orders_27 w ON o.order_id = w.order_id
WHERE o.amount != d.amount OR o.amount != w.amount;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE sales_orders_27 (
    order_id INT,
    amount DECIMAL(10,2)
);
CREATE TABLE delivery_orders_27 (
    order_id INT,
    amount DECIMAL(10,2)
);
CREATE TABLE warehouse_orders_27 (
    order_id INT,
    amount DECIMAL(10,2)
);
-- 示例数据
INSERT INTO sales_orders_27 VALUES (2001, 100.00), (2002, 150.00), (2003, 120.00), (2004, 130.00), (2005, 110.00);
INSERT INTO delivery_orders_27 VALUES (2001, 100.00), (2002, 140.00), (2003, 120.00), (2004, 130.00), (2005, 115.00);
INSERT INTO warehouse_orders_27 VALUES (2001, 100.00), (2002, 150.00), (2003, 110.00), (2004, 130.00), (2005, 110.00);
``` 

## 案例28：批量数据导入后唯一性冲突与自动合并建议  
**业务场景**：数据仓库每日批量导入客户数据，需检测手机号、邮箱等唯一性冲突，并自动生成合并建议（如保留最新、合并积分、标记冲突）。  
**SQL逻辑**：  
1. 用窗口函数分组检测手机号、邮箱重复  
2. 输出冲突记录及合并建议

```sql
WITH dup_customers AS (
    SELECT
        customer_id,
        phone,
        email,
        created_at,
        ROW_NUMBER() OVER (PARTITION BY phone ORDER BY created_at DESC) AS rn_phone,
        ROW_NUMBER() OVER (PARTITION BY email ORDER BY created_at DESC) AS rn_email,
        COUNT(*) OVER (PARTITION BY phone) AS cnt_phone,
        COUNT(*) OVER (PARTITION BY email) AS cnt_email
    FROM customers_28
)
SELECT
    customer_id,
    phone,
    email,
    created_at,
    CASE
        WHEN cnt_phone > 1 THEN '手机号冲突'
        WHEN cnt_email > 1 THEN '邮箱冲突'
        ELSE '正常'
    END AS conflict_type,
    CASE
        WHEN rn_phone = 1 AND cnt_phone > 1 THEN '建议保留最新手机号记录'
        WHEN rn_email = 1 AND cnt_email > 1 THEN '建议保留最新邮箱记录'
        ELSE '建议合并或人工核查'
    END AS fix_suggestion
FROM dup_customers
WHERE cnt_phone > 1 OR cnt_email > 1;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE customers_28 (
    customer_id INT,
    phone VARCHAR(20),
    email VARCHAR(50),
    created_at DATETIME
);
-- 示例数据
INSERT INTO customers_28 VALUES
  (3001, '13800000001', 'a@example.com', '2024-07-01 10:00:00'),
  (3002, '13800000001', 'b@example.com', '2024-07-01 11:00:00'), -- 手机号冲突
  (3003, '13800000002', 'a@example.com', '2024-07-01 12:00:00'), -- 邮箱冲突
  (3004, '13800000003', 'c@example.com', '2024-07-01 13:00:00'),
  (3005, '13800000004', 'd@example.com', '2024-07-01 14:00:00');
``` 

## 案例29：跨系统多字段业务规则一致性与违规溯源  
**业务场景**：保险公司需校验保单、理赔、客户三表间身份证、手机号、保单状态等多字段一致性，并输出所有违规类型及溯源建议。  
**SQL逻辑**：  
1. 多表JOIN校验多字段一致性  
2. CASE WHEN输出违规类型和建议

```sql
SELECT
    p.policy_id,
    c.customer_id,
    cl.claim_id,
    p.id_number AS policy_id_number,
    c.id_number AS customer_id_number,
    cl.id_number AS claim_id_number,
    p.phone AS policy_phone,
    c.phone AS customer_phone,
    cl.phone AS claim_phone,
    CASE
        WHEN p.id_number != c.id_number OR p.id_number != cl.id_number THEN '身份证不一致'
        WHEN p.phone != c.phone OR p.phone != cl.phone THEN '手机号不一致'
        WHEN cl.claim_id IS NOT NULL AND p.status != '有效' THEN '理赔无有效保单'
        ELSE '正常'
    END AS violation_type,
    CASE
        WHEN p.id_number != c.id_number OR p.id_number != cl.id_number THEN '建议同步身份证'
        WHEN p.phone != c.phone OR p.phone != cl.phone THEN '建议同步手机号'
        WHEN cl.claim_id IS NOT NULL AND p.status != '有效' THEN '建议核查保单状态'
        ELSE '无需处理'
    END AS fix_suggestion
FROM policies_29 p
JOIN customers_29 c ON p.customer_id = c.customer_id
LEFT JOIN claims_29 cl ON p.policy_id = cl.policy_id
WHERE
    p.id_number != c.id_number OR p.id_number != cl.id_number
    OR p.phone != c.phone OR p.phone != cl.phone
    OR (cl.claim_id IS NOT NULL AND p.status != '有效');
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE customers_29 (
    customer_id INT,
    id_number VARCHAR(18),
    phone VARCHAR(20)
);
CREATE TABLE policies_29 (
    policy_id INT,
    customer_id INT,
    id_number VARCHAR(18),
    phone VARCHAR(20),
    status VARCHAR(10)
);
CREATE TABLE claims_29 (
    claim_id INT,
    policy_id INT,
    id_number VARCHAR(18),
    phone VARCHAR(20)
);
-- 示例数据
INSERT INTO customers_29 VALUES (4001, '110101199001010011', '13800000001'), (4002, '110101199001010012', '13800000002'), (4003, '110101199001010013', '13800000003'), (4004, '110101199001010014', '13800000004'), (4005, '110101199001010015', '13800000005');
INSERT INTO policies_29 VALUES (5001, 4001, '110101199001010011', '13800000001', '有效'), (5002, 4002, '110101199001010012', '13800000002', '失效'), (5003, 4003, '110101199001010013', '13800000003', '有效'), (5004, 4004, '110101199001010014', '13800000004', '失效'), (5005, 4005, '110101199001010015', '13800000005', '有效');
INSERT INTO claims_29 VALUES (6001, 5001, '110101199001010011', '13800000001'), (6002, 5002, '110101199001010012', '13800000002'), (6003, 5003, '110101199001010013', '13800000003'), (6004, 5004, '110101199001010014', '13800000004'), (6005, 5005, '110101199001010015', '13800000005');
``` 

## 案例30：批量数据缺失与格式异常分组统计与修复建议  
**业务场景**：医疗集团需定期检测病人信息表中身份证、出生日期、联系方式等关键字段的缺失或格式异常，并分组统计异常类型及生成修复建议。  
**SQL逻辑**：  
1. 检查关键字段缺失或格式异常  
2. 分组统计异常类型和数量  
3. 输出异常明细及修复建议

```sql

SELECT
    patient_id,
    patient_name,
    id_number,
    birth_date,
    phone,
    CASE
        WHEN id_number IS NULL OR LENGTH(id_number) != 18 THEN '身份证异常'
        WHEN birth_date IS NULL THEN '出生日期缺失'
        WHEN phone IS NULL OR phone NOT REGEXP '^1[3-9][0-9]{9}$' THEN '手机号异常'
        ELSE '正常'
    END AS anomaly_type,
    CASE
        WHEN id_number IS NULL OR LENGTH(id_number) != 18 THEN '建议补全或修正身份证'
        WHEN birth_date IS NULL THEN '建议补全出生日期'
        WHEN phone IS NULL OR phone NOT REGEXP '^1[3-9][0-9]{9}$' THEN '建议补全或修正手机号'
        ELSE '无需处理'
    END AS fix_suggestion
FROM patients_30
WHERE id_number IS NULL OR LENGTH(id_number) != 18
   OR birth_date IS NULL
   OR phone IS NULL OR phone NOT REGEXP '^1[3-9][0-9]{9}$';
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE patients_30 (
    patient_id INT,
    patient_name VARCHAR(50),
    id_number VARCHAR(18),
    birth_date DATE,
    phone VARCHAR(20)
);
-- 示例数据
INSERT INTO patients_30 VALUES
  (7001, '张三', '110101199001010011', '1990-01-01', '13800000001'),
  (7002, '李四', NULL, '1991-02-02', '13800000002'), -- 身份证缺失
  (7003, '王五', '110101199001010012', NULL, '13800000003'), -- 出生日期缺失
  (7004, '赵六', '110101199001010013', '1992-03-03', '123456'), -- 手机号异常
  (7005, '钱七', '110101199001010014', '1993-04-04', '13800000004');
``` 

## 案例31：物流配送路径优化（基于经纬度的最短路径计算）  
**业务场景**：在物流配送系统中，需要根据订单收货地址和各仓库的地理位置，快速筛选距离订单5公里内的最优配送站点，实现高效的同城配送调度。  
**SQL逻辑**：  
1. 使用ST_Distance_Sphere()函数计算订单地址与仓库的球面距离（单位：米）。  
2. 通过WHERE条件筛选距离小于5000米的仓库。  
3. 按距离升序排序，优先推荐最近的配送站点。

```sql
SELECT
    o.order_id,
    w.warehouse_id,
    w.warehouse_name,
    ST_Distance_Sphere(
        POINT(o.longitude, o.latitude),
        POINT(w.longitude, w.latitude)
    ) AS distance_meters
FROM orders_31 o
JOIN warehouses_31 w
    ON ST_Distance_Sphere(
        POINT(o.longitude, o.latitude),
        POINT(w.longitude, w.latitude)
    ) < 5000
WHERE o.order_id = ?  -- 指定订单
ORDER BY distance_meters ASC
LIMIT 3;  -- 推荐最近的3个仓库
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE orders_31 (
    order_id INT,
    longitude DECIMAL(10,6),
    latitude DECIMAL(10,6)
);
CREATE TABLE warehouses_31 (
    warehouse_id INT,
    warehouse_name VARCHAR(50),
    longitude DECIMAL(10,6),
    latitude DECIMAL(10,6)
);
-- 示例数据
INSERT INTO orders_31 VALUES (8001, 116.397128, 39.916527), (8002, 116.410000, 39.920000), (8003, 116.350000, 39.900000), (8004, 117.000000, 40.000000), (8005, 116.420000, 39.930000);
INSERT INTO warehouses_31 VALUES
  (9001, '仓库A', 116.400000, 39.917000),
  (9002, '仓库B', 116.410000, 39.920000),
  (9003, '仓库C', 116.350000, 39.900000),
  (9004, '仓库D', 117.000000, 40.000000),
  (9005, '仓库E', 116.420000, 39.930000);
``` 

## 案例32：商圈客流量热力分析（地理围栏与区域统计）  
**业务场景**：商业地产运营方希望分析某商场周边3公里内的用户分布密度，评估不同时段的客流量变化，为招商和运营决策提供数据支持。  
**SQL逻辑**：  
1. 使用POLYGON类型存储商圈地理围栏，或以商场为圆心计算3公里范围。  
2. 利用ST_Contains()筛选区域内的用户签到/定位数据。  
3. 按小时分组统计区域内活跃用户数，输出热力分布。

```sql
SELECT
    DATE_FORMAT(locate_time, '%Y-%m-%d %H:00:00') AS hour_slot,
    COUNT(DISTINCT user_id) AS active_users
FROM user_locations_32
WHERE ST_Contains(
        (SELECT geom FROM business_districts_32 WHERE district_id = ?),  -- 商圈多边形
        POINT(longitude, latitude)
    )
  AND locate_time BETWEEN '2024-07-01' AND '2024-07-07'
GROUP BY hour_slot
ORDER BY hour_slot;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE business_districts_32 (
    district_id INT,
    geom POLYGON
);
CREATE TABLE user_locations_32 (
    user_id INT,
    longitude DECIMAL(10,6),
    latitude DECIMAL(10,6),
    locate_time DATETIME
);
-- 示例数据
INSERT INTO business_districts_32 VALUES (1, ST_GeomFromText('POLYGON((116.39 39.91,116.41 39.91,116.41 39.93,116.39 39.93,116.39 39.91))')),
(2, ST_GeomFromText('POLYGON((116.35 39.90,116.37 39.90,116.37 39.92,116.35 39.92,116.35 39.90))')),
(3, ST_GeomFromText('POLYGON((116.41 39.93,116.43 39.93,116.43 39.95,116.41 39.95,116.41 39.93))')),
(4, ST_GeomFromText('POLYGON((116.37 39.92,116.39 39.92,116.39 39.94,116.37 39.94,116.37 39.92))')),
(5, ST_GeomFromText('POLYGON((116.43 39.95,116.45 39.95,116.45 39.97,116.43 39.97,116.43 39.95))'));
INSERT INTO user_locations_32 VALUES
  (10001, 116.400000, 39.920000, '2024-07-01 10:15:00'),
  (10002, 116.405000, 39.915000, '2024-07-01 10:30:00'),
  (10003, 116.420000, 39.930000, '2024-07-01 11:00:00'),
  (10004, 116.410000, 39.925000, '2024-07-01 11:30:00'),
  (10005, 116.415000, 39.935000, '2024-07-01 12:00:00');

``` 

## 案例33：电商实时销售趋势监测（结合Canal与Kafka）  
**业务场景**：电商平台需要实时统计过去10分钟内各品类销售额，并触发库存不足预警，保障促销期间的供应链稳定。  
**SQL逻辑**：  
1. 使用Canal监听MySQL订单表的增量变更，实时推送到Kafka。  
2. 实时计算各品类10分钟销售额（可在流处理平台如Spark Streaming实现，结果写回MySQL）。  
3. 在MySQL侧可做最终聚合和预警查询。

```sql
SELECT
    category_id,
    SUM(order_amount) AS sales_10min
FROM orders_33
WHERE order_time >= NOW() - INTERVAL 10 MINUTE
GROUP BY category_id
HAVING sales_10min > 0;
-- 库存预警可通过触发器或定时任务监控库存表
SELECT
    i.category_id,
    i.stock,
    IFNULL(s.sales_10min, 0) AS sales_10min,
    CASE
        WHEN i.stock < 5 THEN 'CRITICAL: 库存即将耗尽'
        WHEN i.stock < 10 THEN 'WARNING: 库存不足'
        WHEN i.stock < 20 AND IFNULL(s.sales_10min, 0) > 1000 THEN '注意: 热销商品库存紧张'
        ELSE NULL
    END AS alert_message
FROM inventory_33 i
LEFT JOIN (
    SELECT
        category_id,
        SUM(order_amount) AS sales_10min
    FROM orders_33
    WHERE order_time >= NOW() - INTERVAL 10 MINUTE
    GROUP BY category_id
) s ON i.category_id = s.category_id
WHERE i.stock < 20 OR (s.sales_10min > 1000 AND i.stock < 50);
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE orders_33 (
    order_id INT,
    category_id INT,
    order_amount DECIMAL(10,2),
    order_time DATETIME
);
CREATE TABLE inventory_33 (
    product_id INT,
    category_id INT,
    stock INT
);
-- 示例数据
INSERT INTO orders_33 VALUES
  (10001, 1, 200.00, NOW() - INTERVAL 5 MINUTE),
  (10002, 2, 150.00, NOW() - INTERVAL 8 MINUTE),
  (10003, 1, 100.00, NOW() - INTERVAL 12 MINUTE);
INSERT INTO inventory_33 VALUES (20001, 1, 50), (20002, 2, 5);
``` 

## 案例34：金融交易实时风控（动态阈值检测）  
**业务场景**：金融机构需实时监控用户交易金额，若某用户单日累计交易额超过历史均值3倍，则触发风险拦截。  
**SQL逻辑**：  
1. 统计用户近30天每日交易均值  
2. 实时累计当日交易额  
3. 若当日交易额大于3倍均值，则标记为高风险

```sql
WITH user_avg AS (
    SELECT
        user_id,
        AVG(amount) AS avg_amount
    FROM transactions_34
    WHERE transaction_time < CURDATE()  -- 排除今日交易
    GROUP BY user_id
),
user_today AS (
    SELECT
        user_id,
        SUM(amount) AS today_amount
    FROM transactions_34
    WHERE DATE(transaction_time) = CURDATE()
    GROUP BY user_id
)
SELECT
    u.user_id,
    u.today_amount,
    a.avg_amount,
    CASE WHEN u.today_amount > a.avg_amount * 3 THEN '高风险' ELSE '正常' END AS risk_flag
FROM user_today u
JOIN user_avg a ON u.user_id = a.user_id
WHERE u.today_amount > a.avg_amount * 3;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE transactions_34 (
    transaction_id INT PRIMARY KEY,
    user_id INT,
    amount DECIMAL(10,2),
    transaction_time DATETIME
);
-- 示例数据
INSERT INTO transactions_34 VALUES
  (1, 1001, 100.00, NOW() - INTERVAL 1 DAY),
  (2, 1001, 120.00, NOW() - INTERVAL 2 DAY),
  (3, 1001, 90.00, NOW() - INTERVAL 3 DAY),
  (4, 1001, 400.00, NOW()), -- 今日大额
  (5, 1002, 50.00, NOW() - INTERVAL 1 DAY),
  (6, 1002, 60.00, NOW()),
  (7, 1003, 80.00, NOW() - INTERVAL 2 DAY),
  (8, 1003, 70.00, NOW()),
  (9, 1004, 200.00, NOW()),
  (10, 1005, 300.00, NOW());
``` 


## 案例35：用户行为日志的JSON解析与漏斗分析  
**业务场景**：分析用户在APP内的点击路径，统计从"商品详情页"到"支付成功"的转化率，优化产品流程。  
**SQL逻辑**：  
1. 用户行为日志以JSON格式存储，需用JSON_EXTRACT提取关键节点  
2. 统计各漏斗节点的用户数  
3. 计算转化率

```sql
WITH funnel_events AS (
    SELECT
        user_id,
        MAX(CASE WHEN JSON_EXTRACT(event_json, '$.action_type') = 'view_product' THEN 1 ELSE 0 END) AS viewed,
        MAX(CASE WHEN JSON_EXTRACT(event_json, '$.action_type') = 'add_to_cart' THEN 1 ELSE 0 END) AS added_cart,
        MAX(CASE WHEN JSON_EXTRACT(event_json, '$.action_type') = 'pay_success' THEN 1 ELSE 0 END) AS paid
    FROM app_event_logs_35
    WHERE event_time BETWEEN '2024-07-01' AND '2024-07-31'
    GROUP BY user_id
)
SELECT
    COUNT(*) AS total_users,
    SUM(viewed) AS view_product_users,
    SUM(added_cart) AS add_to_cart_users,
    SUM(paid) AS pay_success_users,
    ROUND(SUM(added_cart) * 100.0 / NULLIF(SUM(viewed),0), 2) AS view_to_cart_rate,
    ROUND(SUM(paid) * 100.0 / NULLIF(SUM(added_cart),0), 2) AS cart_to_pay_rate
FROM funnel_events;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE app_event_logs_35 (
    event_id INT PRIMARY KEY,
    user_id INT,
    event_json JSON,
    event_time DATETIME
);
-- 示例数据
INSERT INTO app_event_logs_35 VALUES
  (1, 2001, '{"action_type":"view_product"}', '2024-07-01 10:00:00'),
  (2, 2001, '{"action_type":"add_to_cart"}', '2024-07-01 10:05:00'),
  (3, 2001, '{"action_type":"pay_success"}', '2024-07-01 10:10:00'),
  (4, 2002, '{"action_type":"view_product"}', '2024-07-01 11:00:00'),
  (5, 2002, '{"action_type":"add_to_cart"}', '2024-07-01 11:05:00');
``` 

## 案例36：社交媒体评论情感分析（文本挖掘与SQL结合）  
**业务场景**：对用户评论进行情感分类（正面/中性/负面），并关联产品型号分析质量反馈，辅助产品改进。  
**SQL逻辑**：  
1. 评论文本通过外部NLP工具打标签后写入MySQL  
2. SQL侧统计各产品的情感分布

```sql
SELECT
    product_id,
    sentiment_label,
    COUNT(*) AS comment_count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY product_id), 2) AS sentiment_percent
FROM product_comments_36
WHERE comment_date BETWEEN '2024-06-01' AND '2024-06-30'
GROUP BY product_id, sentiment_label
ORDER BY product_id, sentiment_label;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE product_comments_36 (
    comment_id INT PRIMARY KEY,
    product_id INT,
    user_id INT,
    comment_text TEXT,
    sentiment_label VARCHAR(10),
    comment_date DATE
);
-- 示例数据
INSERT INTO product_comments_36 VALUES
  (1, 101, 1001, '很好用，推荐！', '正面', '2024-06-01'),
  (2, 101, 1002, '一般般', '中性', '2024-06-02'),
  (3, 101, 1003, '质量差', '负面', '2024-06-03'),
  (4, 101, 1004, '性价比高', '正面', '2024-06-04'),
  (5, 101, 1005, '还可以', '中性', '2024-06-05'),
  (6, 102, 1006, '外观漂亮', '正面', '2024-06-01'),
  (7, 102, 1007, '不太满意', '负面', '2024-06-02'),
  (8, 102, 1008, '功能齐全', '正面', '2024-06-03'),
  (9, 102, 1009, '一般', '中性', '2024-06-04'),
  (10, 102, 1010, '售后好', '正面', '2024-06-05');


``` 

## 案例37：动态行转置报表（销售数据按商品与日期交叉展示）  
**业务场景**：生成日报表，横向展示各商品在不同日期的销售数量，支持灵活的多维分析。  
**SQL逻辑**：  
1. 动态SQL拼接CASE WHEN实现行转列  
2. 按日期分组聚合

```sql
SELECT
    sale_date,
    MAX(CASE WHEN product_name = '商品A' THEN sale_qty END) AS 商品A,
    MAX(CASE WHEN product_name = '商品B' THEN sale_qty END) AS 商品B,
    MAX(CASE WHEN product_name = '商品C' THEN sale_qty END) AS 商品C
FROM sales_daily_37
WHERE sale_date BETWEEN '2024-07-01' AND '2024-07-07'
GROUP BY sale_date
ORDER BY sale_date;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE sales_daily_37 (
    id INT PRIMARY KEY,
    sale_date DATE,
    product_name VARCHAR(20),
    sale_qty INT
);
-- 示例数据
INSERT INTO sales_daily_37 VALUES
  (1, '2024-07-01', '商品A', 10),
  (2, '2024-07-01', '商品B', 8),
  (3, '2024-07-01', '商品C', 5),
  (4, '2024-07-02', '商品A', 12),
  (5, '2024-07-02', '商品B', 7),
  (6, '2024-07-02', '商品C', 6),
  (7, '2024-07-03', '商品A', 9),
  (8, '2024-07-03', '商品B', 10),
  (9, '2024-07-03', '商品C', 7),
  (10, '2024-07-04', '商品A', 11),
  (11, '2024-07-04', '商品B', 9),
  (12, '2024-07-04', '商品C', 8),
  (13, '2024-07-05', '商品A', 13),
  (14, '2024-07-05', '商品B', 6),
  (15, '2024-07-05', '商品C', 9);
``` 

## 案例38：动态指标仪表盘（跨部门数据联动分析）  
**业务场景**：在BI系统中实时展示各地区销售额、利润率、库存周转率的联动变化，支持多维度下钻。  
**SQL逻辑**：  
1. WITH子句预计算基础指标  
2. 多表JOIN实现多维联动  
3. 结果供前端仪表盘动态展示

```sql

WITH sales_base AS (
    SELECT region, SUM(amount) AS sales_amount FROM sales_38 GROUP BY region
),
profit_base AS (
    SELECT region, SUM(profit) AS profit_amount FROM profits_38 GROUP BY region
),
inventory_base AS (
    SELECT region, SUM(turnover_days) AS total_turnover FROM inventory_38 GROUP BY region
)
SELECT
    s.region,
    s.sales_amount,
    p.profit_amount,
    ROUND(p.profit_amount / NULLIF(s.sales_amount,0), 2) AS profit_rate,
    i.total_turnover
FROM sales_base s
JOIN profit_base p ON s.region = p.region
JOIN inventory_base i ON s.region = i.region
ORDER BY s.region;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE sales_38 (
    id INT PRIMARY KEY,
    region VARCHAR(20),
    amount DECIMAL(10,2)
);
CREATE TABLE profits_38 (
    id INT PRIMARY KEY,
    region VARCHAR(20),
    profit DECIMAL(10,2)
);
CREATE TABLE inventory_38 (
    id INT PRIMARY KEY,
    region VARCHAR(20),
    turnover_days INT
);
-- 示例数据
INSERT INTO sales_38 VALUES
  (1, '华东', 10000.00), (2, '华东', 12000.00), (3, '华南', 8000.00), (4, '华南', 9000.00), (5, '华北', 11000.00),
  (6, '华北', 9500.00), (7, '西南', 7000.00), (8, '西南', 8500.00), (9, '东北', 6000.00), (10, '东北', 6500.00);
INSERT INTO profits_38 VALUES
  (1, '华东', 3000.00), (2, '华东', 3500.00), (3, '华南', 2000.00), (4, '华南', 2500.00), (5, '华北', 3200.00),
  (6, '华北', 2800.00), (7, '西南', 1800.00), (8, '西南', 2100.00), (9, '东北', 1500.00), (10, '东北', 1700.00);
INSERT INTO inventory_38 VALUES
  (1, '华东', 30), (2, '华东', 28), (3, '华南', 35), (4, '华南', 33), (5, '华北', 27),
  (6, '华北', 29), (7, '西南', 40), (8, '西南', 38), (9, '东北', 45), (10, '东北', 42);
``` 

## 案例39：金融交易操作审计（满足GDPR与等保2.0要求）  
**业务场景**：记录所有用户对敏感表（如客户信息表）的增删改操作，并生成可追溯的审计报告，满足合规要求。  
**SQL逻辑**：  
1. 开启MySQL审计功能，记录操作日志  
2. 定期分析审计日志，统计敏感操作次数和用户分布

```sql
SELECT
    user_host,
    event_time,
    command_type,
    argument
FROM mysql_audit_log_39
WHERE argument LIKE '%customer_info%'
  AND command_type IN ('UPDATE', 'DELETE')
  AND event_time BETWEEN '2024-07-01' AND '2024-07-31'
ORDER BY event_time DESC;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE mysql_audit_log_39 (
    id INT PRIMARY KEY,
    user_host VARCHAR(100),
    event_time DATETIME,
    command_type VARCHAR(20),
    argument TEXT
);
-- 示例数据
INSERT INTO mysql_audit_log_39 VALUES
  (1, 'user1@localhost', '2024-07-01 10:00:00', 'UPDATE', 'UPDATE customer_info SET name = ...'),
  (2, 'user2@localhost', '2024-07-02 11:00:00', 'DELETE', 'DELETE FROM customer_info WHERE ...'),
  (3, 'user3@localhost', '2024-07-03 12:00:00', 'UPDATE', 'UPDATE customer_info SET phone = ...'),
  (4, 'user1@localhost', '2024-07-04 13:00:00', 'DELETE', 'DELETE FROM customer_info WHERE ...'),
  (5, 'user2@localhost', '2024-07-05 14:00:00', 'UPDATE', 'UPDATE customer_info SET address = ...');
``` 

## 案例40：供应链数据一致性校验（跨系统业务规则审计）  
**业务场景**：确保采购订单、库存变更、物流状态在多个系统间的一致性，避免数据孤岛和业务风险。  
**SQL逻辑**：  
1. 跨表JOIN校验关键字段一致性  
2. 输出差异报告

```sql
SELECT
    po.order_id,
    po.order_status,
    inv.inventory_status,
    log.logistics_status,
    CASE
        WHEN po.order_status != inv.inventory_status THEN '订单与库存状态不一致'
        WHEN po.order_status != log.logistics_status THEN '订单与物流状态不一致'
        ELSE '一致'
    END AS diff_type
FROM purchase_orders_40 po
LEFT JOIN inventory_records_40 inv ON po.order_id = inv.order_id
LEFT JOIN logistics_records_40 log ON po.order_id = log.order_id
WHERE po.order_status != inv.inventory_status
   OR po.order_status != log.logistics_status;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE purchase_orders_40 (
    order_id INT PRIMARY KEY,
    order_status VARCHAR(20)
);
CREATE TABLE inventory_records_40 (
    id INT PRIMARY KEY,
    order_id INT,
    inventory_status VARCHAR(20)
);
CREATE TABLE logistics_records_40 (
    id INT PRIMARY KEY,
    order_id INT,
    logistics_status VARCHAR(20)
);
-- 示例数据
INSERT INTO purchase_orders_40 VALUES
  (1001, '已完成'), (1002, '待发货'), (1003, '已取消'), (1004, '已完成'), (1005, '待发货');
INSERT INTO inventory_records_40 VALUES
  (1, 1001, '已完成'), (2, 1002, '待发货'), (3, 1003, '已取消'), (4, 1004, '待发货'), (5, 1005, '已完成');
INSERT INTO logistics_records_40 VALUES
  (1, 1001, '已完成'), (2, 1002, '已完成'), (3, 1003, '已取消'), (4, 1004, '待发货'), (5, 1005, '待发货');
``` 

## 案例41：销售数据趋势预测（LAG/LEAD与线性回归结合）  
**业务场景**：基于过去12个月的销售数据，预测未来3个月的销售额，为经营决策提供数据支持。  
**SQL逻辑**：  
1. 使用LAG获取滞后12期数据  
2. 可结合外部工具做线性回归预测，预测结果写回MySQL  
3. SQL侧可做简单移动平均预测

```sql
SELECT
    month,
    sales_amount,
    AVG(sales_amount) OVER (ORDER BY month ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS moving_avg_3m
FROM monthly_sales_41
WHERE month BETWEEN '2023-07' AND '2024-06'
ORDER BY month;
-- 线性回归预测建议用Python等工具处理后写回MySQL
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE monthly_sales_41 (
    id INT PRIMARY KEY,
    month VARCHAR(7),
    sales_amount DECIMAL(10,2)
);
-- 示例数据
INSERT INTO monthly_sales_41 VALUES
  (1, '2023-07', 10000.00), (2, '2023-08', 11000.00), (3, '2023-09', 12000.00), (4, '2023-10', 13000.00), (5, '2023-11', 12500.00),
  (6, '2023-12', 14000.00), (7, '2024-01', 13500.00), (8, '2024-02', 14500.00), (9, '2024-03', 15000.00), (10, '2024-04', 15500.00),
  (11, '2024-05', 16000.00), (12, '2024-06', 16500.00);
``` 

## 案例42：电力消耗异常检测（滚动标准差与Z-score）  
**业务场景**：识别工厂设备的异常用电行为（如超出历史均值3倍标准差），及时预警设备故障或异常。  
**SQL逻辑**：  
1. 计算24小时滚动均值和标准差  
2. 计算Z-score，筛选异常点

```sql
WITH power_stats AS (
    SELECT
        device_id,
        timestamp,
        power_usage,
        AVG(power_usage) OVER (PARTITION BY device_id ORDER BY timestamp ROWS BETWEEN 24 PRECEDING AND CURRENT ROW) AS avg_usage_24h,
        STDDEV_SAMP(power_usage) OVER (PARTITION BY device_id ORDER BY timestamp ROWS BETWEEN 24 PRECEDING AND CURRENT ROW) AS std_usage_24h,
        (power_usage - AVG(power_usage) OVER (PARTITION BY device_id ORDER BY timestamp ROWS BETWEEN 24 PRECEDING AND CURRENT ROW)) /
        NULLIF(STDDEV_SAMP(power_usage) OVER (PARTITION BY device_id ORDER BY timestamp ROWS BETWEEN 24 PRECEDING AND CURRENT ROW), 0) AS z_score
    FROM device_power_logs_42
    WHERE timestamp BETWEEN '2024-06-01' AND '2024-06-30'
)
SELECT * FROM power_stats
WHERE ABS(z_score) > 1;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE device_power_logs_42 (
    id INT PRIMARY KEY,
    device_id INT,
    timestamp DATETIME,
    power_usage DECIMAL(10,2)
);
-- 示例数据
INSERT INTO device_power_logs_42 VALUES
  (1, 101, '2024-06-01 00:00:00', 100.0),
  (2, 101, '2024-06-01 01:00:00', 105.0),
  (3, 101, '2024-06-01 02:00:00', 98.0),
  (4, 101, '2024-06-01 03:00:00', 102.0),
  (5, 101, '2024-06-01 04:00:00', 300.0), -- 异常
  (6, 102, '2024-06-01 00:00:00', 80.0),
  (7, 102, '2024-06-01 01:00:00', 82.0),
  (8, 102, '2024-06-01 02:00:00', 79.0),
  (9, 102, '2024-06-01 03:00:00', 81.0),
  (10, 102, '2024-06-01 04:00:00', 200.0); -- 异常
``` 

## 案例43：电商商品关联推荐（Apriori算法SQL实现）  
**业务场景**：根据购物篮数据生成"买了A又买B"的关联规则，例如"购买笔记本电脑的用户80%会购买鼠标"，用于提升电商平台的交叉销售能力。
**SQL逻辑**：
1. 通过三重自连接生成商品组合，统计商品对的支持度。
2. 计算置信度，筛选高置信度的商品组合用于推荐。

```sql
-- 计算频繁项集（支持度≥5%）
WITH item_pairs AS (
  SELECT
    t1.order_id,
    t1.item_id AS item_a,
    t2.item_id AS item_b,
    t1.item_name AS item_a_name,
    t2.item_name AS item_b_name
  FROM order_items_43 t1
  JOIN order_items_43 t2
    ON t1.order_id = t2.order_id
    AND t1.item_id < t2.item_id
),
support_stats AS (
  SELECT
    item_a,
    item_b,
    item_a_name,
    item_b_name,
    COUNT(DISTINCT order_id) AS pair_count,
    COUNT(DISTINCT order_id) / (SELECT COUNT(DISTINCT order_id) FROM order_items_43) AS support
  FROM item_pairs
  GROUP BY item_a, item_b, item_a_name, item_b_name
  HAVING COUNT(DISTINCT order_id) >= 2  -- 至少共同出现在2个订单中
),
confidence_stats AS (
  SELECT
    a.item_a,
    a.item_b,
    a.item_a_name,
    a.item_b_name,
    a.pair_count,
    a.support,
    a.support / NULLIF((
      SELECT COUNT(DISTINCT order_id)
      FROM order_items_43
      WHERE item_id = a.item_a
    ) / (SELECT COUNT(DISTINCT order_id) FROM order_items_43), 0) AS confidence
  FROM support_stats a
)
SELECT
  item_a_name || ' → ' || item_b_name AS rule,
  pair_count,
  ROUND(support, 3) AS support,
  ROUND(confidence, 3) AS confidence
FROM confidence_stats
WHERE confidence >= 0.5  -- 降低置信度阈值
ORDER BY confidence DESC, support DESC;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE order_items (
    id INT PRIMARY KEY,
    order_id INT,
    item_id INT,
    item_name VARCHAR(50)
);
-- 示例数据
INSERT INTO order_items VALUES
  (1, 1001, 201, '笔记本电脑'),
  (2, 1001, 202, '鼠标'),
  (3, 1001, 203, '键盘'),
  (4, 1002, 201, '笔记本电脑'),
  (5, 1002, 202, '鼠标'),
  (6, 1002, 204, '显示器'),
  (7, 1003, 202, '鼠标'),
  (8, 1003, 203, '键盘'),
  (9, 1003, 205, 'U盘'),
  (10, 1004, 201, '笔记本电脑'),
  (11, 1004, 202, '鼠标'),
  (12, 1004, 203, '键盘'),
  (13, 1005, 201, '笔记本电脑'),
  (14, 1005, 204, '显示器'),
  (15, 1005, 205, 'U盘');
``` 

## 案例44：基于用户行为的协同过滤推荐（余弦相似度SQL计算）  
**业务场景**：为用户推荐相似用户喜爱的商品，实现"相似用户还买过"功能，提升个性化推荐效果。
**SQL逻辑**：
1. 构建用户-商品交互矩阵。
2. 计算用户间余弦相似度，筛选高相似度用户对。

```sql
-- 构建用户行为矩阵（1表示交互，0表示未交互）
WITH user_item_matrix AS (
  SELECT user_id, item_id, 1 AS interaction
  FROM user_item_interactions_44
  GROUP BY user_id, item_id
),
user_norm AS (
  SELECT user_id, SQRT(COUNT(*)) AS norm
  FROM user_item_matrix
  GROUP BY user_id
),
user_similarity AS (
  SELECT
    a.user_id AS user_a,
    b.user_id AS user_b,
    COUNT(*) AS common_items,
    COUNT(*) / (na.norm * nb.norm) AS cosine_sim
  FROM user_item_matrix a
  JOIN user_item_matrix b ON a.item_id = b.item_id AND a.user_id < b.user_id
  JOIN user_norm na ON a.user_id = na.user_id
  JOIN user_norm nb ON b.user_id = nb.user_id
  GROUP BY a.user_id, b.user_id, na.norm, nb.norm
  HAVING COUNT(*) > 1  -- 至少有2个共同项目
)
SELECT
  user_a,
  user_b,
  common_items,
  ROUND(cosine_sim, 3) AS cosine_similarity
FROM user_similarity
ORDER BY cosine_similarity DESC, common_items DESC;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE user_item_interactions_44 (
    id INT PRIMARY KEY,
    user_id INT,
    item_id INT
);
-- 示例数据
INSERT INTO user_item_interactions_44 VALUES
  (1, 101, 201), (2, 101, 202), (3, 101, 203), (4, 102, 201), (5, 102, 202),
  (6, 102, 204), (7, 103, 202), (8, 103, 203), (9, 103, 205), (10, 104, 201),
  (11, 104, 202), (12, 104, 203), (13, 105, 201), (14, 105, 204), (15, 105, 205);

``` 

## 案例45：金融行业用户风险标签建模（多维度规则引擎）  
**业务场景**：根据交易频率、金额、设备变更等维度生成"高风险用户"标签，辅助金融风控和反欺诈。
**SQL逻辑**：
1. 使用窗口函数和CASE WHEN构建多维度风险标签。
2. 结合动态阈值和行为特征输出风险分层。

```sql
WITH user_stats AS (
  SELECT
    user_id,
    COUNT(*) AS trans_freq,
    AVG(amount) AS avg_amount,
    MAX(transaction_time) AS last_trans_time
  FROM transactions_45
  GROUP BY user_id
),
device_location_stats AS (
  SELECT
    user_id,
    COUNT(DISTINCT device_id) AS device_changes,
    COUNT(DISTINCT location) AS location_changes
  FROM transactions_45
  GROUP BY user_id
),
combined_stats AS (
  SELECT
    u.user_id,
    u.trans_freq,
    u.avg_amount,
    u.last_trans_time,
    d.device_changes,
    l.location_changes,
    (SELECT AVG(trans_freq) FROM user_stats) * 1.5 AS high_freq_threshold
  FROM user_stats u
  JOIN device_location_stats d ON u.user_id = d.user_id
  JOIN device_location_stats l ON u.user_id = l.user_id
)
SELECT
  user_id,
  CASE
    WHEN trans_freq > high_freq_threshold AND avg_amount > 5000 THEN '高风险-高频大额'
    WHEN device_changes > 3 AND location_changes > 2 THEN '高风险-设备异常'
    WHEN trans_freq > 20 AND last_trans_time < NOW() - INTERVAL 7 DAY THEN '高风险-异常活跃'
    ELSE '正常'
  END AS risk_label
FROM combined_stats;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE transactions_45 (
    id INT PRIMARY KEY,
    user_id INT,
    amount DECIMAL(10,2),
    device_id INT,
    location VARCHAR(50),
    transaction_time DATETIME
);
-- 示例数据
INSERT INTO transactions_45 VALUES
  (1, 1001, 6000.00, 201, '北京', NOW() - INTERVAL 1 DAY),
  (2, 1001, 7000.00, 202, '上海', NOW() - INTERVAL 2 DAY),
  (3, 1001, 8000.00, 203, '广州', NOW() - INTERVAL 3 DAY),
  (4, 1001, 9000.00, 204, '深圳', NOW() - INTERVAL 4 DAY),
  (5, 1001, 10000.00, 205, '杭州', NOW() - INTERVAL 5 DAY),
  (6, 1002, 2000.00, 201, '北京', NOW() - INTERVAL 1 DAY),
  (7, 1002, 2500.00, 202, '上海', NOW() - INTERVAL 2 DAY),
  (8, 1002, 3000.00, 203, '广州', NOW() - INTERVAL 3 DAY),
  (9, 1002, 3500.00, 204, '深圳', NOW() - INTERVAL 4 DAY),
  (10, 1002, 4000.00, 205, '杭州', NOW() - INTERVAL 5 DAY);
``` 

## 案例46：医疗数据脱敏查询（动态数据Masking）  
**业务场景**：允许分析师查询疾病统计数据，但隐藏患者姓名、身份证号等敏感信息，满足医疗数据合规要求。
**SQL逻辑**：
1. 创建脱敏视图，动态隐藏敏感字段。
2. 支持统计分析但不暴露原始敏感数据。

```sql
-- 创建脱敏视图
SELECT
  CONCAT(SUBSTRING(name, 1, 1), '**', SUBSTRING(name, LENGTH(name)-1)) AS masked_name,
  CONCAT(SUBSTRING(id_card, 1, 6), '**********', SUBSTRING(id_card, LENGTH(id_card)-3)) AS masked_id_card,
  disease_type,
  gender,
  age,
  COUNT(*) OVER (PARTITION BY disease_type, gender, age) AS case_count
FROM patient_records_46;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE patient_records_46 (
    id INT PRIMARY KEY,
    name VARCHAR(20),
    id_card VARCHAR(18),
    disease_type VARCHAR(20),
    gender VARCHAR(10),
    age INT
);
-- 示例数据
INSERT INTO patient_records_46 VALUES
  (1, '张三', '110101199001010011', '高血压', '男', 45),
  (2, '李四', '110101199002020022', '糖尿病', '女', 50),
  (3, '王五', '110101199003030033', '高血压', '男', 60),
  (4, '赵六', '110101199004040044', '冠心病', '女', 55),
  (5, '钱七', '110101199005050055', '高血压', '男', 65),
  (6, '孙八', '110101199006060066', '糖尿病', '女', 52),
  (7, '周九', '110101199007070077', '高血压', '男', 70);
``` 

## 案例47：多渠道归因模型（位置归因法SQL实现）  
**业务场景**：计算各营销渠道（搜索、社交、广告）在用户转化路径中的贡献值，优化营销资源分配。
**SQL逻辑**：
1. 通过窗口函数识别转化路径中的首次与末次触点。
2. 按规则分配权重，统计各渠道贡献。

```sql
WITH user_touch_paths AS (
  SELECT user_id, touch_time, channel, is_conversion,
         ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY touch_time) AS first_touch,
         ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY touch_time DESC) AS last_touch
  FROM marketing_touches_47
)
SELECT channel,
       COUNT(DISTINCT CASE WHEN first_touch = 1 AND is_conversion = 1 THEN user_id END) * 0.4 AS first_weight,
       COUNT(DISTINCT CASE WHEN last_touch = 1 AND is_conversion = 1 THEN user_id END) * 0.4 AS last_weight,
       COUNT(DISTINCT CASE WHEN first_touch > 1 AND last_touch > 1 AND is_conversion = 1 THEN user_id END) * 0.2 AS middle_weight,
       (COUNT(DISTINCT CASE WHEN first_touch = 1 AND is_conversion = 1 THEN user_id END) * 0.4 +
        COUNT(DISTINCT CASE WHEN last_touch = 1 AND is_conversion = 1 THEN user_id END) * 0.4 +
        COUNT(DISTINCT CASE WHEN first_touch > 1 AND last_touch > 1 AND is_conversion = 1 THEN user_id END) * 0.2)
        AS total_contribution
FROM user_touch_paths
GROUP BY channel
ORDER BY total_contribution DESC;
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE marketing_touches_47 (
    id INT PRIMARY KEY,
    user_id INT,
    touch_time DATETIME,
    channel VARCHAR(20),
    is_conversion TINYINT
);
-- 示例数据
INSERT INTO marketing_touches_47 VALUES
  (1, 1001, '2024-07-01 10:00:00', '搜索', 0),
  (2, 1001, '2024-07-01 12:00:00', '广告', 1),
  (3, 1002, '2024-07-01 09:00:00', '社交', 0),
  (4, 1002, '2024-07-01 11:00:00', '广告', 1),
  (5, 1003, '2024-07-01 08:00:00', '搜索', 0),
  (6, 1003, '2024-07-01 10:00:00', '社交', 1),
  (7, 1004, '2024-07-01 07:00:00', '广告', 0),
  (8, 1004, '2024-07-01 09:00:00', '搜索', 1),
  (9, 1005, '2024-07-01 06:00:00', '社交', 0),
  (10, 1005, '2024-07-01 08:00:00', '广告', 1);
``` 

## 案例48：广告点击率提升实验显著性分析  
**业务场景**：某互联网公司上线新广告样式，需对比实验组与对照组的点击率，判断新样式是否显著提升转化。  
**SQL逻辑**：  
1. 分别统计实验组和对照组的曝光数与点击数  
2. 计算点击率及标准误差  
3. 计算Z值判断显著性

```sql
WITH stats AS (
SELECT group_id,
        COUNT(*) AS impressions,
        SUM(CASE WHEN is_click=1 THEN 1 ELSE 0 END) AS clicks
FROM ad_events_48
WHERE event_date BETWEEN '2024-07-01' AND '2024-07-07'
GROUP BY group_id
)
SELECT
a.group_id AS group_a, b.group_id AS group_b,
a.clicks*1.0/a.impressions AS ctr_a,
b.clicks*1.0/b.impressions AS ctr_b,
(a.clicks*1.0/a.impressions - b.clicks*1.0/b.impressions) /
SQRT(a.clicks/a.impressions/a.impressions + b.clicks/b.impressions/b.impressions) AS z_score
FROM stats a, stats b
WHERE a.group_id = 'experiment' AND b.group_id = 'control';
```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE ad_events_48 (
    id INT PRIMARY KEY,
    group_id VARCHAR(20),
    is_click TINYINT,
    event_date DATE
);
-- 示例数据
INSERT INTO ad_events_48 VALUES
  (1, 'experiment', 1, '2024-07-01'),
  (2, 'experiment', 0, '2024-07-01'),
  (3, 'experiment', 1, '2024-07-02'),
  (4, 'experiment', 0, '2024-07-02'),
  (5, 'experiment', 1, '2024-07-03'),
  (6, 'control', 0, '2024-07-01'),
  (7, 'control', 1, '2024-07-01'),
  (8, 'control', 0, '2024-07-02'),
  (9, 'control', 1, '2024-07-02'),
  (10, 'control', 0, '2024-07-03');
``` 

## 案例49：SaaS产品注册-激活-付费漏斗分析  
**业务场景**：SaaS公司需分析用户从注册到激活再到付费的各环节转化率，优化产品引导流程。
**SQL逻辑**：
 1. 统计每个用户是否完成注册、激活、付费  
 2. 汇总各环节人数及转化率

 ```sql
WITH funnel AS (
   SELECT user_id,
          MAX(CASE WHEN action='register' THEN 1 ELSE 0 END) AS registered,
          MAX(CASE WHEN action='activate' THEN 1 ELSE 0 END) AS activated,
          MAX(CASE WHEN action='pay' THEN 1 ELSE 0 END) AS paid
   FROM user_actions_49
   WHERE action_time BETWEEN '2024-07-01' AND '2024-07-31'
   GROUP BY user_id
 )
 SELECT
   COUNT(*) AS total_users,
   SUM(registered) AS registered_users,
   SUM(activated) AS activated_users,
   SUM(paid) AS paid_users,
   ROUND(SUM(activated)*100.0/NULLIF(SUM(registered),0),2) AS reg_to_act_rate,
   ROUND(SUM(paid)*100.0/NULLIF(SUM(activated),0),2) AS act_to_pay_rate
 FROM funnel;
 ```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE user_actions_49 (
    id INT PRIMARY KEY,
    user_id INT,
    action VARCHAR(20),
    action_time DATETIME
);
-- 示例数据
INSERT INTO user_actions_49 VALUES
  (1, 1001, 'register', '2024-07-01 10:00:00'),
  (2, 1001, 'activate', '2024-07-01 11:00:00'),
  (3, 1001, 'pay', '2024-07-01 12:00:00'),
  (4, 1002, 'register', '2024-07-01 10:30:00'),
  (5, 1002, 'activate', '2024-07-01 11:30:00'),
  (6, 1003, 'register', '2024-07-01 10:45:00'),
  (7, 1003, 'activate', '2024-07-01 11:45:00'),
  (8, 1004, 'register', '2024-07-01 10:50:00'),
  (9, 1005, 'register', '2024-07-01 10:55:00'),
  (10, 1005, 'activate', '2024-07-01 11:55:00'),
  (11, 1005, 'pay', '2024-07-01 12:55:00');
``` 

## 案例50：跨平台广告归因与ROI分析  
**业务场景**：品牌方投放广告于多个平台（如抖音、快手、微信），需分析各平台对最终转化的归因贡献及ROI，优化预算分配。
**SQL逻辑**：
1. 统计每个平台的触点数、转化数和花费
2. 计算归因转化率和ROI
 ```sql
 SELECT
   platform,
   COUNT(DISTINCT user_id) AS touch_users,
   SUM(CASE WHEN is_conversion=1 THEN 1 ELSE 0 END) AS conversions,
   SUM(ad_cost) AS total_cost,
   ROUND(SUM(CASE WHEN is_conversion=1 THEN 1 ELSE 0 END)*100.0/COUNT(DISTINCT user_id),2) AS conversion_rate,
   ROUND(SUM(revenue)/NULLIF(SUM(ad_cost),0),2) AS roi
 FROM ad_touchpoints_50
 GROUP BY platform
 ORDER BY roi DESC;
 ```

**DDL语句和示例数据**
```sql
-- DDL
CREATE TABLE ad_touchpoints_50 (
    id INT PRIMARY KEY,
    platform VARCHAR(20),
    user_id INT,
    is_conversion TINYINT,
    ad_cost DECIMAL(10,2),
    revenue DECIMAL(10,2)
);
-- 示例数据
INSERT INTO ad_touchpoints_50 VALUES
  (1, '抖音', 1001, 1, 50.00, 200.00),
  (2, '抖音', 1002, 0, 30.00, 0.00),
  (3, '快手', 1003, 1, 40.00, 150.00),
  (4, '快手', 1004, 0, 20.00, 0.00),
  (5, '微信', 1005, 1, 60.00, 250.00),
  (6, '微信', 1006, 0, 25.00, 0.00),
  (7, '抖音', 1007, 1, 55.00, 210.00),
  (8, '快手', 1008, 0, 35.00, 0.00),
  (9, '微信', 1009, 1, 65.00, 260.00),
  (10, '抖音', 1010, 0, 28.00, 0.00);
``` 